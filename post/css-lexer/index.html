<!DOCTYPE html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width"><link rel=alternate type=application/atom+xml href=/atom.xml title=宝硕博客><meta property=og:site_name content=宝硕博客><link rel=canonical href=https://blog.baoshuo.ren/post/css-lexer/ ><meta name=twitter:site content=@renbaoshuo><meta name=twitter:creator content=@renbaoshuo><title>实现一个 CSS 词法分析器（Lexer） - 宝硕博客</title><meta name=description content="最近在实习的时候，遇到了一些需求，需要自己去实现 CSS 的解析、（伪）渲染流程。以之为契机，我学习了一下编译相关的知识，其中的第一环就是 Lexer。"><meta property=og:description content="最近在实习的时候，遇到了一些需求，需要自己去实现 CSS 的解析、（伪）渲染流程。以之为契机，我学习了一下编译相关的知识，其中的第一环就是 Lexer。"><meta name=keywords content="[object Object],[object Object]"><meta property=og:type content=article><meta property=og:title content="实现一个 CSS 词法分析器（Lexer） - 宝硕博客"><meta property=og:url content=/post/css-lexer/ ><meta property=og:image content=https://s1.baoshuo.ren/2025/08/05/GeYRiDgPyqwrCLU.jpg><meta name=twitter:card content=summary_large_image><meta name=next-head-count content=16><meta name=darkreader content=disabled><meta name=generator content="Hexo 6.2.0"><script defer nomodule="" src=/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js></script><script src=/_next/static/chunks/webpack-0b13f59efd3a755f.js defer></script><script src=/_next/static/chunks/framework-114634acb84f8baa.js defer></script><script src=/_next/static/chunks/main-e1d878da14378316.js defer></script><script src=/_next/static/chunks/pages/_app-e77a89313e72302b.js defer></script><script src=/_next/static/chunks/6-5d8180322feff14f.js defer></script><script src=/_next/static/chunks/pages/post/%5Bslug%5D-49a4108d40c022d5.js defer></script><script src=/_next/static/byBUxtXb822vQt9-WWC4i/_buildManifest.js defer></script><script src=/_next/static/byBUxtXb822vQt9-WWC4i/_ssgManifest.js defer></script><style>.lc{pointer-events:none}.oc{height:2px}.pc{z-index:200}.uc{box-shadow:0 0 10px var(--c-a),0 0 10px var(--c-a)}.vc{opacity:1}.tc{transition:all .25s ease-in-out}.wc{transform:rotate(3deg) translateY(-4px)}.xc{width:5%}.Wh:before{box-shadow:inset 0 0 32px}.Xh:before{height:3px}.Yh:before{left:1.5px}.Zh:before{top:14px}.ai:before{width:3px}.bi:after{box-sizing:border-box}.gi:after{transform:translate(-50%,-50%)}.oi:after{box-shadow:inset 0 0 0 2px,0 0 0 2px}.pi:after{height:27.5px}.qi:after{left:0}.ri:after{top:100%}.si:after{width:27.5px}.ti:before{height:.8em}.wi:before{transform:translate(0) rotate(45deg)}.xi:before{width:.8em}.zi:after{top:80%}.Ai:after{left:80%}.Bi:after{transform:translate(-50%,-50%) rotate(45deg)}.Ci:after{width:.5em}.Rh{font-size:16px}.Ii:before{height:100%}.vi:before{top:0}.ui:before{left:0}.Ri:after{height:14px}.Si:after{width:7px}.Ti:after{top:1px}.Ve{height:2rem}.We{align-items:stretch}.Md:after{content:"·"}.cg:before{transform:translate(-50%,-25%) rotate(45deg)}.Of:before{box-sizing:border-box}.eg:before{box-shadow:0 -.35em,0 .35em}.fg:before{transform:translate(-50%,-50%)}.gg:before{width:100%}.Nc{right:1rem}.Oc{bottom:1rem}.Pc{contain:layout}.Wc{line-height:1}.n{justify-content:center}.if{flex-grow:0}.Ed{flex-grow:0}.nc{top:0}.sc{height:100%}.k{left:0}.Yb{font-size:1.25rem}.Zb{width:95%}.ac{max-width:var(--w)}.mb{color:var(--c)}.Pb{word-break:keep-all}.Dc{contain:content}.Bc{text-align:center}.ld{color:#fff}.Cc{user-select:none}.Mf{text-indent:-9999px}.Lf{height:1em}.Kf{width:1em}.Tg:before{transform:translate(-25%,-50%) rotate(-45deg)}.dg:before{width:.65em}.bg:before{height:.65em}.Rf:before{top:50%}.Qf:before{left:50%}.we{font-size:.9em}.xe{font-weight:500}.ye{flex-grow:1}.De{justify-content:flex-end}.Ee{text-align:right}.o{align-items:center}.hg{box-sizing:border-box}.Ic{display:block}.Hg:after{display:block}.Sg:after{left:1px}.mc{position:fixed}.Xb{box-shadow:var(--s)}.Td{z-index:100}.Yd::-webkit-scrollbar{height:var(--s-x)}.Zd::-webkit-scrollbar{width:var(--s-y)}.ob{justify-content:space-between}.ge{letter-spacing:1px}.Xc{cursor:pointer}.Jc{font-size:.9rem}.a{display:inline-block}.h{position:absolute}.Nf{vertical-align:middle}.Zg{font-size:.925rem}.ah{height:12.25em}.bh{width:12.25em}.ch{right:-30px}.dh{top:-40px}.eh{opacity:.1}.Pf:before{content:""}.Sf:before{position:absolute}.wh:before{height:3.75em}.xh:before{width:3.75em}.yh:before{left:1.5625em}.zh:before{top:3em}.Gg:after{content:""}.Ig:after{position:absolute}.Nh:after{height:3.75em}.Oh:after{width:3.75em}.Ph:after{right:1.5625em}.Qh:after{top:3em}.E{position:relative}.d{font-weight:700}.pb{color:var(--c-s)}.kd{font-size:.9em}.m{display:flex}.kb{flex-direction:column}.Ke{font-size:.8em}.Lb{color:inherit}.K{width:100%}.Gb{max-height:400px}.Hb{object-fit:cover}.A{font-size:1.75rem}.B{letter-spacing:.75px}.Kb{color:var(--c-m)}.rc{background-color:var(--c-a)}.ci:after{border-top-left-radius:100px}.di:after{border-top-right-radius:100px}.ei:after{border-bottom-right-radius:100px}.fi:after{border-bottom-left-radius:100px}.Sh:before{border-top-left-radius:100px}.Th:before{border-top-right-radius:100px}.Uh:before{border-bottom-right-radius:100px}.Vh:before{border-bottom-left-radius:100px}.Ji:before{border-top-left-radius:1000px}.Ki:before{border-top-right-radius:1000px}.Li:before{border-bottom-right-radius:1000px}.Mi:before{border-bottom-left-radius:1000px}.Ni:after{overflow-x:hidden}.Oi:after{overflow-y:hidden}.Pi:after{border-top-left-radius:1000px}.Qi:after{border-bottom-left-radius:1000px}.jf{flex-basis:0}.qc{background-color:transparent}.Se{padding-right:.7rem}.Ue{padding-left:.7rem}.Kd{margin-right:.4rem}.Ld{margin-left:.4rem}.yc{padding-top:2.5rem}.Ac{padding-bottom:4rem}.Rc{padding-top:.9rem}.Sc{padding-right:.9rem}.Tc{padding-bottom:.9rem}.Uc{padding-left:.9rem}.Re{padding-top:.6rem}.Te{padding-bottom:.6rem}.Qb{background-color:var(--g-m)}.Vb{overflow-x:auto}.Mc{text-decoration-line:inherit}.se{padding-top:.75rem}.bc{margin-right:auto}.cc{margin-left:auto}.te{background-color:#946ce6}.qd{border-top-left-radius:.25rem}.rd{border-top-right-radius:.25rem}.sd{border-bottom-right-radius:.25rem}.td{border-bottom-left-radius:.25rem}.ue{padding-top:.25rem}.zc{padding-right:1rem}.ve{padding-bottom:.25rem}.ub{padding-left:1rem}.Ug{margin-left:.5rem}.ze{flex-shrink:1}.Ae{flex-basis:50%}.Nb{padding-right:.5rem}.Ob{padding-left:.5rem}.Lg:after{background-color:currentColor}.Qc{background-color:var(--g-b)}.Rb{border-top-left-radius:var(--r)}.Sb{border-top-right-radius:var(--r)}.Tb{border-bottom-right-radius:var(--r)}.Ub{border-bottom-left-radius:var(--r)}.Wb{overflow-y:auto}.ae::-webkit-scrollbar-thumb{background-color:#b5b5b5}.be::-webkit-scrollbar-thumb{border-top-left-radius:var(--r)}.ce::-webkit-scrollbar-thumb{border-top-right-radius:var(--r)}.de::-webkit-scrollbar-thumb{border-bottom-right-radius:var(--r)}.ee::-webkit-scrollbar-thumb{border-bottom-left-radius:var(--r)}.nd{padding-top:0}.Vc{margin-top:.5rem}.F{padding-top:1.5rem}.H{padding-bottom:1.5rem}.Fe{margin-right:.5rem}.jh{border-top-left-radius:50%}.kh{border-top-right-radius:50%}.lh{border-bottom-right-radius:50%}.mh{border-bottom-left-radius:50%}.rh:before{border-top-left-radius:50%}.sh:before{border-top-right-radius:50%}.th:before{border-bottom-right-radius:50%}.uh:before{border-bottom-left-radius:50%}.Ih:after{border-top-left-radius:50%}.Jh:after{border-top-right-radius:50%}.Kh:after{border-bottom-right-radius:50%}.Lh:after{border-bottom-left-radius:50%}.Ge{background-color:var(--g-l)}.He{padding-bottom:1.25rem}.ud{overflow-x:hidden}.vd{overflow-y:hidden}.Ie{text-decoration-line:underline}.Je{flex-wrap:wrap}.J{margin-top:1rem}.qb{flex-shrink:0}.Rd{margin-right:1rem}.sb{margin-bottom:1rem}.nb{text-decoration-line:none}.s{margin-top:0}.u{margin-bottom:0}.w{padding-top:1.25rem}.x{padding-right:2rem}.y{padding-bottom:0}.z{padding-left:2rem}.C{margin-top:.75rem}.t{margin-right:0}.D{margin-bottom:.75rem}.v{margin-left:0}.M{padding-top:.5rem}.Ib{padding-right:0}.N{padding-bottom:.5rem}.Jb{padding-left:0}.hi:after{border-top-width:4px}.ii:after{border-right-width:4px}.ji:after{border-bottom-width:4px}.ki:after{border-left-width:4px}.li:after{border-top-color:transparent}.mi:after{border-bottom-color:transparent}.ni:after{border-left-color:transparent}.yi:after{border-top-width:2px}.kf{border-top-style:none}.lf{border-right-style:none}.mf{border-bottom-style:none}.nf{border-left-style:none}.Xf:before{border-top-width:2px}.Yf:before{border-right-width:0}.Zf:before{border-bottom-width:0}.ag:before{border-left-width:2px}.Vg:before{border-top-width:0}.Wg:before{border-right-width:2px}.Xg:before{border-bottom-width:2px}.Yg:before{border-left-width:0}.fh{border-top-width:1.125em}.gh{border-right-width:1.125em}.hh{border-bottom-width:1.125em}.ih{border-left-width:1.125em}.R{border-top-style:solid}.f{border-right-style:solid}.S{border-bottom-style:solid}.T{border-left-style:solid}.nh:before{border-top-width:1em}.oh:before{border-right-width:1em}.ph:before{border-bottom-width:1em}.qh:before{border-left-width:1em}.Tf:before{border-top-style:solid}.Uf:before{border-right-style:solid}.Vf:before{border-bottom-style:solid}.Wf:before{border-left-style:solid}.vh:before{border-right-color:transparent}.Ah:after{border-top-width:1em}.Bh:after{border-right-width:1em}.Ch:after{border-bottom-width:1em}.Dh:after{border-left-width:1em}.Eh:after{border-top-style:solid}.Fh:after{border-right-style:solid}.Gh:after{border-bottom-style:solid}.Hh:after{border-left-style:solid}.Mh:after{border-right-color:transparent}@media (min-width:769px){.Ne{padding-top:0}.Oe{padding-right:1rem}.Pe{padding-bottom:0}.Qe{padding-left:1rem}.Ec{padding-top:2.5rem}.Fc{padding-right:3rem}.Gc{padding-bottom:4rem}.Hc{padding-left:3rem}.Kc{display:flex}.Lc{justify-content:space-between}}@media (max-width:768px){.Le{flex-direction:column}.Me{align-items:center}}.Mb:hover{color:var(--c-a)}.re:hover{background-color:var(--g-n)}*,:after,:before{box-sizing:border-box}html{-moz-tab-size:4;tab-size:4;line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0;font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji}code,pre{font-family:ui-monospace,SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;font-size:1em}button{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button{text-transform:none}button{-webkit-appearance:button}:root{--g:#f2f5f8;--g-m:#fff;--g-b:#fff;--g-s:#f6f7f8;--g-p:#f6f8fa;--g-c:rgba(174,184,193,.2);--g-n:rgba(67,90,111,.06);--g-t:#fff;--g-l:#f5f5f5;--g-i:#fff;--g-r:hsla(200,5%,89%,.5);--c:#2f3d4e;--c-a:#0969da;--c-s:#57606a;--c-m:#6f767d;--h6:#57606b;--b:#d8dee4;--b-t:#d0d7de;--r:0.5rem;--s-y:0.5rem;--s-x:0.35rem;--w:1000px;--s:0 4px 10px rgba(0,2,4,.06),0 0 1px rgba(0,2,4,.11);--i:0}@media(max-width:768px){:root{--s-y:0.35rem;--s-x:0.28rem}}@media(prefers-color-scheme:dark){:root:not(.light){color-scheme:dark;--g:#121212;--g-m:#21262d;--g-b:#364151;--g-s:#2f3542;--g-p:#161b22;--g-c:hsla(215,8%,47%,.4);--g-n:#3e4b5e;--g-t:#2f3542;--g-l:#2c343c;--g-i:#3b3b3b;--g-r:rgba(51,61,77,.5);--c:#c9d1d9;--c-a:#58a6ff;--c-s:#8b949e;--c-m:hsla(0,0%,100%,.659);--h6:#8b949e;--b:#757575;--b-t:#5f5f5f;--s:none;--i:1}:root:not(.light) img{filter:brightness(.8)}}body{line-height:1.5;background:var(--g);font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,PingFang SC,Hiragino Sans GB,Source Han Sans SC,Noto Sans CJK SC,Microsoft YaHei,WenQuanYi Micro Hei,WenQuanYi Zen Hei,Helvetica Neue,Arial,sans-serif;color:var(--c);overflow-y:scroll}#__next{display:flex;flex-direction:column;justify-content:space-between;min-height:100vh}*{transition:background-color .25s ease-in-out}a{color:var(--c-a);text-decoration:none}#post_markdown__nRdJ1{line-height:1.5;word-wrap:break-word}#post_markdown__nRdJ1>:first-child{margin-top:0!important}#post_markdown__nRdJ1>:last-child{margin-bottom:0!important}#post_markdown__nRdJ1 a{color:var(--c-a);-webkit-text-decoration:underline transparent;text-decoration:underline transparent;text-underline-position:under;transition:-webkit-text-decoration-color 75ms ease-in-out;transition:text-decoration-color 75ms ease-in-out;transition:text-decoration-color 75ms ease-in-out,-webkit-text-decoration-color 75ms ease-in-out}#post_markdown__nRdJ1 a:active,#post_markdown__nRdJ1 a:hover{outline-width:0}#post_markdown__nRdJ1 a:hover{-webkit-text-decoration:underline var(--c-a);text-decoration:underline var(--c-a)}#post_markdown__nRdJ1 h2,#post_markdown__nRdJ1 h3{margin-top:1.5rem;margin-bottom:1rem;font-weight:700;line-height:1.25}#post_markdown__nRdJ1 h2{font-size:1.5em}#post_markdown__nRdJ1 h3{font-size:1.25em}#post_markdown__nRdJ1 p{margin-top:0;margin-bottom:.625rem}#post_markdown__nRdJ1 blockquote{margin:0;padding:0 1em;color:var(--c-s);border-left:.25em solid var(--b-t)}#post_markdown__nRdJ1 blockquote>:first-child{margin-top:0}#post_markdown__nRdJ1 blockquote>:last-child{margin-bottom:0}#post_markdown__nRdJ1 ul{margin-top:0;margin-bottom:0;padding-left:2em}#post_markdown__nRdJ1 ul ul{margin-top:0;margin-bottom:0}#post_markdown__nRdJ1 li>p{margin-top:16px}#post_markdown__nRdJ1 li+li{margin-top:.25em}#post_markdown__nRdJ1 code{font-family:ui-monospace,SFMono-Regular,SF Mono,Menlo,Consolas,Liberation Mono,monospace;font-size:.75em;margin:0;padding:.2em .4em;background-color:var(--g-c);border-radius:6px}#post_markdown__nRdJ1 pre{padding:1rem;overflow:auto;font-size:.85em;line-height:1.45;background-color:var(--g-p);border-radius:6px;word-wrap:normal}#post_markdown__nRdJ1 pre::-webkit-scrollbar{height:var(--s-x);width:var(--s-y)}#post_markdown__nRdJ1 pre::-webkit-scrollbar-thumb{background:#b5b5b5;border-radius:var(--r)}#post_markdown__nRdJ1 pre code{font-size:100%;display:inline;max-width:auto;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background:transparent;border:0}#post_markdown__nRdJ1 blockquote,#post_markdown__nRdJ1 p,#post_markdown__nRdJ1 pre,#post_markdown__nRdJ1 ul{margin-top:0;margin-bottom:1rem}#post_markdown__nRdJ1 .hljs-keyword,#post_markdown__nRdJ1 .hljs-type{color:#d73a49}#post_markdown__nRdJ1 .hljs-literal,#post_markdown__nRdJ1 .hljs-number{color:#005cc5}#post_markdown__nRdJ1 .hljs-string{color:#032f62}#post_markdown__nRdJ1 .hljs-comment{color:#6a737d}</style><link rel=stylesheet href=/_next/static/css/962347f4f84b175e.css data-n-g="" media=print onload="this.media='all'"><noscript><link rel=stylesheet href=/_next/static/css/962347f4f84b175e.css></noscript><link rel=stylesheet href=/_next/static/css/d7033cd71835a0bf.css data-n-g="" media=print onload="this.media='all'"><noscript><link rel=stylesheet href=/_next/static/css/d7033cd71835a0bf.css></noscript><link rel=stylesheet href=/_next/static/css/0f22a5d8313376b7.css data-n-p="" media=print onload="this.media='all'"><noscript><link rel=stylesheet href=/_next/static/css/0f22a5d8313376b7.css></noscript><noscript data-n-css=""></noscript></head><body><div id=__next><div class="lc mc k nc K oc pc qc"><div class="sc rc tc" style=opacity:0;width:0%><div class="h xc sc tc uc vc wc" style=left:-5.5%></div></div></div><div><nav class="m ob Qb Cc Xb Pc E Td Le Me Ne Oe Pe Qe" role=navigation><a class="m Ed qb o Yb d Lb nb Re Se Te Ue ge" href=/ ><svg id=Main xmlns=http://www.w3.org/2000/svg viewBox="0 0 512 512" class="Ve Fe"><path d=M471,256A214.8122,214.8122,0,0,1,256,471a216.4337,216.4337,0,0,1-40.955-3.896A214.86,214.86,0,0,1,41,256,214.9809,214.9809,0,0,1,256,41a214.4584,214.4584,0,0,1,154.4137,65.4129q6.911,7.1214,13.146,14.8661c1.3337,1.6587,2.6413,3.3258,3.9229,5.0281A214.5854,214.5854,0,0,1,471,256Z fill=#5897d1></path><path d=M419.2572,204.2572A163.1145,163.1145,0,0,1,256,367.5136a164.3664,164.3664,0,0,1-31.0985-2.9579A163.271,163.271,0,1,1,419.2572,204.2572Z fill=#9fc5e6></path><path d=M418.8558,63.0971v44.65A10.5833,10.5833,0,0,1,408.2729,118.33H333.7074V52.5134h74.5655A10.584,10.584,0,0,1,418.8558,63.0971Z fill=#ff668c></path><path d=M329.7492,458.0118A215.2574,215.2574,0,0,1,60.2534,345.0537l67.6679-90.0019a30.79,30.79,0,0,1,49.2216,0l38.5328,51.2574Z fill=#343a6e></path><path d=M408.6937,77.1989a8.2229,8.2229,0,0,1-8.2229,8.223H371.8716a8.2271,8.2271,0,0,0,0,16.4542h9.8724a8.2271,8.2271,0,1,1,0,16.4542H333.7065V52.5134h46.87a8.2238,8.2238,0,0,1,8.2229,8.2313,8.2246,8.2246,0,0,0,8.2313,8.2229h3.44A8.23,8.23,0,0,1,408.6937,77.1989Z fill=#ef487d></path><path d=M328.6658,41.0008h0a7.2391,7.2391,0,0,0-7.2394,7.24V230.2126h14.4789V48.24A7.24,7.24,0,0,0,328.6658,41.0008Z fill=#f9df73></path><path d=M454.3619,339.0513q-2.87,6.8317-6.1872,13.4266A215.3468,215.3468,0,0,1,215.045,467.104a214.1378,214.1378,0,0,1-82.1653-34.83L299.2368,211.0171a36.8115,36.8115,0,0,1,58.8571,0Z fill=#484b7f></path><path d=M328.67,196.3173c-5.6429,0-11.285,4.8972-15.0584,14.699L215.045,467.104a213.7775,213.7775,0,0,1-82.1653-34.83L299.2461,211.0171A36.578,36.578,0,0,1,328.67,196.3173Z fill=#343a6e></path><path d=M448.1747,352.4779A215.3468,215.3468,0,0,1,215.045,467.104a213.4209,213.4209,0,0,1-59.4366-20.9382L264.82,337.7974c-17.0068,44.185,31.1885,55.6372,81.2087,37.2085C391.9237,358.0939,396.8116,340.0692,448.1747,352.4779Z fill=#343a6e></path><path d=M215.6766,306.31c-25.6245.886-50.9072,16.0419-67.0884,16.0419-25.0106,0-54.584-22.1845-20.6661-67.2992a30.79,30.79,0,0,1,49.2216,0Z fill=#484b7f></path></svg><span>宝硕博客</span></a><div class="m We Vb Yd Zd ae be ce de ee"><a class="m Ed qb o Lb nb Re Se Te Ue re" href=/ >首页</a><a class="m Ed qb o Lb nb Re Se Te Ue re" href=/archives/ >归档</a><a class="m Ed qb o Lb nb Re Se Te Ue re" href=/categories/ >分类</a><a class="m Ed qb o Lb nb Re Se Te Ue re" href=/tags/ >标签</a><a class="m Ed qb o Lb nb Re Se Te Ue re" href=https://baoshuo.ren/friends/ >友链</a><a class="m Ed qb o Lb nb Re Se Te Ue re" href=/about/ >关于</a><a class="m Ed qb o Lb nb Re Se Te Ue re" href=/atom.xml><i class="a E Kf Lf Mf Nf Rh ud vd Pf Of Sf Sh Th Uh Vh fg Wh Xh Yh Zh ai Gg bi Ig ci di ei fi gi hi ii ji ki Eh Fh Gh Hh li Mh mi ni oi pi qi ri si"></i></a><a class="m Ed qb o Lb nb Re Se Te Ue re" href=/search/ ><i class="hg a Rh Lf Kf E Mf Nf Pf Sf Xf Wg Xg ag Tf Uf Vf Wf Sh Th Uh Vh ti ui vi wi xi Gg Ig yi Eh zi Ai Bi Ci"></i></a><div class="if ze jf"><button class="Xc sc m o n Re Se Te Ue kf lf mf nf qc re"><i class="a Rh Lf Kf E Mf Nf Pf Sf gg Ii Xf Wg Xg ag Tf Uf Vf Wf Ji Ki Li Mi vi ui Gg Ig Hg Lg Ni Oi Pi Qi Ri Si Ti Sg"></i></button></div></div></nav><main><article class="Qb Rb Sb Tb Ub Vb Wb Xb Zb ac J bc sb cc"><img class="K Gb Hb" src=https://s1.baoshuo.ren/2025/08/05/GeYRiDgPyqwrCLU.jpg alt="实现一个 CSS 词法分析器（Lexer）"><header class="s t u v M x y z"><h1 class="C t D v A B">实现一个 CSS 词法分析器（Lexer）</h1><div class="M Ib N Jb Kb"><time datetime=2025-08-05T15:18:52.000Z>2025-08-05</time><span class="s Kd u Ld Md"></span><a class="Lb nb Mb" href=/categories/%E6%8A%80%E6%9C%AF%E5%90%91/ >技术向</a><span class="s Kd u Ld Md"></span><span>约 5.2 千字</span></div></header><section class="s t u v se x H z Dc" id=post_markdown__nRdJ1><p>最近在实习的时候，遇到了一些需求，需要自己去实现 CSS 的解析、（伪）渲染流程。以之为契机，我学习了一下编译相关的知识，其中的第一环就是 Lexer。</p><span id=more></span><p>本文中的代码均使用 Go 实现，成果已经作为 Go 库 <a href=https://pkg.go.dev/go.baoshuo.dev/csslexer rel="external nofollow noreferrer"><code>go.baoshuo.dev/csslexer</code></a> 发布。</p><ul><li>GitHub 仓库：<a href=https://github.com/renbaoshuo/go-css-lexer rel="external nofollow noreferrer">renbaoshuo/go-css-lexer</a></li><li>实现标准：<a href=https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/ rel="external nofollow noreferrer">CSS Syntax Module Level 3 (W3C Candidate Recommendation Draft; 24 December 2021)</a></li></ul><p><em>建议在阅读本文前对 CSS 标准内容有一定理解。</em></p><h2 id=词法分析>词法分析</h2><blockquote><p>词法分析（lexical analysis）是计算机科学中将字符序列转换为记号（token，也有译为标记或词元）序列的过程。进行词法分析的程序或者函数叫作词法分析器（lexical analyzer，简称 lexer），也叫扫描器（scanner）。词法分析器一般以函数的形式存在，供语法分析器调用。</p><p><cite>——维基百科</cite></p></blockquote><p>词法分析是编译中的第一个步骤。它读入组成源码的字符流，并将他们组织成一个个的词素（lexeme）。有了词素以后，识别并标注它的类型，就可以生成一个 <code>&lt;token-name, attribute-value&gt;</code> 形式的词法单元（token）。这个单元会被传送给下一个步骤 —— 语法分析 —— 进行后续的处理。</p><p>在进行词法分析之前，首先要设定好到底有多少种 token 类型，然后再确定每个 token 类型的判断条件和解析方式。</p><h2 id=token-的分类>Token 的分类</h2><p>由 CSS Syntax Module Level 3 中的 <a href=https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#tokenization rel="external nofollow noreferrer">4. Tokenization</a> 一节可以得到 CSS 的 token 有以下几种类型：</p><pre><code class="hljs text">&lt;ident-token&gt;
&lt;function-token&gt;
&lt;at-keyword-token&gt;
&lt;hash-token&gt;
&lt;string-token&gt;
&lt;bad-string-token&gt;
&lt;url-token&gt;
&lt;bad-url-token&gt;
&lt;delim-token&gt;
&lt;number-token&gt;
&lt;percentage-token&gt;
&lt;dimension-token&gt;
&lt;whitespace-token&gt;
&lt;CDO-token&gt;
&lt;CDC-token&gt;
&lt;colon-token&gt;
&lt;semicolon-token&gt;
&lt;comma-token&gt;
&lt;[-token&gt;
&lt;]-token&gt;
&lt;(-token&gt;
&lt;)-token&gt;
&lt;{-token&gt;
&lt;}-token&gt;</code></pre><p>为了解析方便，我们又在标准的 token 类型外拓展了几个 token 类型，得到了下面的 token 表：</p><pre><code class="hljs text">&lt;ident-token&gt;         IdentToken
&lt;function-token&gt;      FunctionToken            foo()
&lt;at-keyword-token&gt;    AtKeywordToken           @foo
&lt;hash-token&gt;          HashToken                #foo
&lt;string-token&gt;        StringToken
&lt;bad-string-token&gt;    BadStringToken
&lt;url-token&gt;           UrlToken                 url()
&lt;bad-url-token&gt;       BadUrlToken
&lt;delim-token&gt;         DelimiterToken
&lt;number-token&gt;        NumberToken              3
&lt;percentage-token&gt;    PercentageToken          3%
&lt;dimension-token&gt;     DimensionToken           3em
&lt;whitespace-token&gt;    WhitespaceToken
&lt;CDO-token&gt;           CDOToken                 &lt;!--
&lt;CDC-token&gt;           CDCToken                 --&gt;
&lt;colon-token&gt;         ColonToken               :
&lt;semicolon-token&gt;     SemicolonToken           ;
&lt;comma-token&gt;         CommaToken               ,
&lt;(-token&gt;             LeftParenthesisToken     (
&lt;)-token&gt;             RightParenthesisToken    )
&lt;[-token&gt;             LeftBracketToken         [
&lt;]-token&gt;             RightBracketToken        ]
&lt;{-token&gt;             LeftBraceToken           {
&lt;}-token&gt;             RightBraceToken          }
&lt;EOF-token&gt;           EOFToken

CommentToken          /* ... */
IncludeMatchToken     ~=
DashMatchToken        |=
PrefixMatchToken      ^=
SuffixMatchToken      $=
SubstringMatchToken   *=
ColumnToken           ||
UnicodeRangeToken</code></pre><p>于是乎，我们就有了词法分析的期望目标产物 —— 由这 33 种类型的 token 组成的 token 流。</p><h2 id=输入流>输入流</h2><blockquote><p>工欲善其事，必先利其器。</p></blockquote><p>在实现真正的词法分析流程以前，我们需要编写一套输入流来辅助我们完成读入的操作。</p><p>首先，我们给出输入流的定义：</p><pre><code class="hljs go"><span class=hljs-comment>// Input represents a stream of runes read from a source.</span>
<span class=hljs-keyword>type</span> Input <span class=hljs-keyword>struct</span> {
    runes []<span class=hljs-type>rune</span> <span class=hljs-comment>// The runes in the input stream.</span>
    pos   <span class=hljs-type>int</span>    <span class=hljs-comment>// The current position in the input stream.</span>
    start <span class=hljs-type>int</span>    <span class=hljs-comment>// The start position of the current token being read.</span>
    err   <span class=hljs-type>error</span>  <span class=hljs-comment>// Any error encountered while reading the input.</span>
}</code></pre><p>这个结构封装了对一个 rune 切片的访问，并维护了当前扫描的位置（pos）和当前正在扫描的 token 的起始位置（start）。</p><p>需要注意的是，我们使用 <code>rune</code> 而不是 <code>byte</code> 来存储内容，这样做的原因是为了便于处理代码中包含的 Emoji 等 Unicode 字符。</p><p>为了使用方便，这个输入流可以从 <code>string</code>、<code>[]rune</code>、<code>[]byte</code> 和 <code>io.Reader</code> 初始化。实现细节可以查看仓库中的 <a href=https://github.com/renbaoshuo/go-css-lexer/blob/master/input.go rel="external nofollow noreferrer"><code>input.go</code></a>，各个函数签名如下：</p><ul><li><code>NewInput(input string) *Input</code></li><li><code>NewInputRunes(runes []rune) *Input</code></li><li><code>NewInputBytes(input []byte) *Input</code></li><li><code>NewInputReader(r io.Reader) *Input</code></li></ul><p>接下来，我们需要设计一系列合理的方法，使得这个输入流的使用能够在满足我们的实际需求的同时，还保持简洁的风格。</p><p>在 4.2 节的一系列定义中，通过观察不难发现，在解析过程中会不断地出现 consume 和 reconsume 的操作，也就是说，在输入流的末尾会不断地进行 pop_back 和 push_back 的操作。那么我们可以将这些操作转化为「预读」和「后移指针」的操作，以此来减少频繁在流末尾进行的弹出和插入操作。</p><p>于是，我们就有了以下两个方法：</p><ul><li><p><code>func (z *Input) Peek(n int) rune</code></p><p>预读输入流中 <code>pos+n</code> 位置的字符。</p></li><li><p><code>func (z *Input) Move(n int)</code></p><p>将当前输入流的指针后移 <code>n</code> 位。</p></li></ul><p>经过阅读规范以后，不难发现一个 token 可以由几个不同类别的字符序列组成，比如 <code>16px</code> 就是一个 <code>16</code> (number sequence) 和一个 <code>px</code> (ident sequence) 共同组成的 dimension-token。所以我们在解析一个 token 的时候可能会调用多个解析函数，那么就需要在 token 级别做一个固定的输出模式。</p><p>于是，我们定义 <code>func (z *Input) Shift() []rune</code> 来弹出当前 token，并更新 <code>Input</code> 实例中的 <code>start</code> 值，以开始下一 token 的解析。</p><p>不过后续在解析 url-token 的时候遇到了需要读取当前已经 consume 的内容的情况，于是将 <code>Shift</code> 方法拆分成了 <code>Current</code> 和 <code>Shift</code> 两个不同的方法，以便使用。</p><p>除此以外，在解析的时候还有需要在满足某一特定条件下一直 consume 的能力需求，因此又设计了较为通用的 <code>func (z *Input) MoveWhilePredicate(pred func(rune) bool)</code> 方法，来实现这一能力。</p><p>加上错误处理逻辑以后，整个 <code>Input</code> 的方法如下：</p><pre><code class="hljs go"><span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(z *Input)</span></span> PeekErr(pos <span class=hljs-type>int</span>) <span class=hljs-type>error</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(z *Input)</span></span> Err() <span class=hljs-type>error</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(z *Input)</span></span> Peek(n <span class=hljs-type>int</span>) <span class=hljs-type>rune</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(z *Input)</span></span> Move(n <span class=hljs-type>int</span>)
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(z *Input)</span></span> Current() []<span class=hljs-type>rune</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(z *Input)</span></span> Shift() []<span class=hljs-type>rune</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(z *Input)</span></span> MoveWhilePredicate(pred <span class=hljs-function><span class=hljs-keyword>func</span><span class=hljs-params>(<span class=hljs-type>rune</span>)</span></span> <span class=hljs-type>bool</span>)</code></pre><p>接下来，我们就可以正式开始 lexer 的编写了。</p><h2 id=词法分析器>词法分析器</h2><p>其实 Lexer 的方法框架设计就相对简单了，下面直接给出定义：</p><pre><code class="hljs go"><span class=hljs-keyword>type</span> Lexer <span class=hljs-keyword>struct</span> {
    r *Input <span class=hljs-comment>// The input stream of runes to be lexed.</span>
}

<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> Err() <span class=hljs-type>error</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> Next() (TokenType, []<span class=hljs-type>rune</span>)</code></pre><p>在 <code>Next</code> 方法中有一个巨大的 switch-case 语句，这里面包含了 <a href=https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-token rel="external nofollow noreferrer">4.3.1. Consume a token</a> 中所描述的所有在 token 开始时的情形。我们将会根据一个 token 开始的几个字符（小于等于 3 个）来确定这个 token 的后续部分应该如何解析。</p><h3 id=token-开始处的分类讨论>Token 开始处的分类讨论</h3><p>开始解析 token 的时候一定是在文件流的开头或者上一个 token 刚刚解析完毕的时候，那么此时我们只需要根据对应规则判断 token 类型即可。</p><p>首先预读 1 个字符，记为 <code>next</code>，然后对这个字符进行分类讨论。</p><ul><li><p><code>EOF</code>：直接返回 EOF-token。</p></li><li><p><code>\t</code>, <code>\n</code>, <code>\r</code>, <code>\f</code>, <code></code>：根据标准需要将此字符及后续的所有 whitespace 组合成一个 whitespace-token。</p></li><li><p><code>/</code>：如果是 <code>/*</code> 则一直读取到 <code>*/</code> 或者 <code>EOF</code> 作为 comment-token。</p></li><li><p><code>'</code> (单引号), <code>"</code>(双引号)：遇到这两种引号，会调用字符串解析函数 <code>consumeStringToken()</code>。该函数会持续读取字符，直到遇到与之匹配的结束引号。在此过程中，它会处理转义字符（如 <code>\"</code>）。如果在中途遇到换行符或文件末尾，则会生成一个 bad-string-token，否则生成一个 string-token。</p></li><li><p><code>0</code> ~ <code>9</code> 的数字字符：如果以数字开头，确定无疑是数字类型，调用数字解析函数 <code>consumeNumericToken()</code>。</p></li><li><p><code>(</code>, <code>)</code>, <code>[</code>, <code>]</code>, <code>{</code>, <code>}</code>：生成对应的括号字符。function-token 或者 url-token 的情况会在处理 ident-like 的时候另行考虑。</p></li><li><p><code>+</code>, <code>.</code>：这两个字符，再加上 <code>-</code>，都比较特殊。不过 <code>-</code> 需要包含一些额外的判断，因此归属于另外一条规则处理。</p><ul><li>解析器会向后预读，通过 <code>nextCharsAreNumber()</code> 判断后续字符是否能构成一个合法的数字（例如 <code>+1.5</code>, <code>.5</code>）。</li><li>如果可以，则调用 <code>consumeNumericToken()</code> 将其完整解析为一个 numeric-token。</li><li>如果不构成数字，则 <code>+</code> 和 <code>.</code> 会被当作 delimiter-token。</li></ul></li><li><p><code>-</code>：除了像 <code>+</code> 一样判断是否有可能进入数字的处理逻辑以外，还需要考虑作为 <code>--&gt;</code> (CDC-token) 和 ident-like 的情况。如果都不是才会被当做 delimiter-token。</p><pre><code class="hljs go"><span class=hljs-keyword>if</span> l.nextCharsAreNumber() {
    <span class=hljs-keyword>return</span> l.consumeNumericToken()
}
<span class=hljs-keyword>if</span> l.r.Peek(<span class=hljs-number>1</span>) == <span class=hljs-string>'-'</span> &amp;&amp; l.r.Peek(<span class=hljs-number>2</span>) == <span class=hljs-string>'&gt;'</span> {
    l.r.Move(<span class=hljs-number>3</span>) <span class=hljs-comment>// consume "--&gt;"</span>
    <span class=hljs-keyword>return</span> CDCToken, l.r.Shift()
}
<span class=hljs-keyword>if</span> l.nextCharsAreIdentifier() {
    <span class=hljs-keyword>return</span> l.consumeIdentLikeToken()
}
l.r.Move(<span class=hljs-number>1</span>)
<span class=hljs-keyword>return</span> DelimiterToken, l.r.Shift()</code></pre></li><li><p><code>&lt;</code>：如果能构成 <code>&lt;!--</code>，解析为一个 CDO-token，否则解析为 delimiter-token。</p></li><li><p><code>*</code>, <code>^</code>, <code>$</code>, <code>|</code>, <code>~</code>: 这些是属性选择器中的匹配符。</p><ul><li>如果它们后面紧跟 <code>=</code>，则会组合成一个专有 token：<ul><li><code>*=</code> → substring-match-token</li><li><code>^=</code> → prefix-match-token</li><li><code>$=</code> → suffix-match-token</li><li><code>~=</code> → include-match-token</li><li><code>|=</code> → dash-match-token</li></ul></li><li>特别地，对于 <code>|</code>，如果能够组成 <code>||</code>，则会成为 column-token。</li><li>如果没有，则单独作为 delimiter-token。</li></ul></li><li><p><code>@</code>：如果后续的字符能够组成一个 identifier，那么解析为 at-keyword-token，否则解析为 delimiter-token。</p></li><li><p><code>,</code> (逗号)：直接生成 comma-token。</p></li><li><p><code>:</code> (冒号)：直接生成 colon-token。</p></li><li><p><code>;</code> (分号)：直接生成 semicolon-token。</p></li><li><p><code>u</code> 或 <code>U</code>：这是一个特殊前缀。如果其后是 + 紧跟着十六进制数字或 ? (例如 U+26 或 u+A?)，则调用 <code>consumeUnicodeRangeToken()</code> 解析为一个 urange-token。否则，按标识符处理。</p><ul><li>这里有一个坑点，需要在编写 parser 的时候注意，比如 <code>u+a</code> 既是一个合法的 unicode-range，也是一个合法的 selector，需要根据上下文来判定。</li></ul></li><li><p>1 &lt;= c &lt;= 31, <code>!</code>, <code>%</code>, <code>&amp;</code>, <code>=</code>, <code>&gt;</code>, <code>?</code>, <code>`</code>, 127：解析为 delimiter-token。</p></li><li><p>其余字符：尝试解析为 ident-like。</p></li></ul><p>整个流程在 <a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/lexer.go#L24-L198 rel="external nofollow noreferrer"><code>lexer.go</code> 的 24-198 行</a>，由于篇幅原因此处就不贴完整代码了。</p><h3 id=token-解析>Token 解析</h3><p>为了方便，我们为几种逻辑复杂 / 需要重用的 token 解析逻辑进行了封装，产生了如下函数：</p><ul><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume_token.go#L3-L16 rel="external nofollow noreferrer"><code>consumeNumericToken()</code></a></p><ul><li>先 consume 一个数字；</li><li>如果后续跟一个合法的 name，则 consume 这个 name 作为它的单位，组合为 dimension-token；</li><li>如果后续跟一个 <code>%</code>，consume 掉这个 <code>%</code>，产生一个 percentage-token；</li><li>否则产生一个 number-token。</li></ul><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-numeric-token</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeNumericToken() (TokenType, []<span class=hljs-type>rune</span>) {
    l.consumeNumber()

    <span class=hljs-keyword>if</span> l.nextCharsAreIdentifier() {
        l.consumeName()
        <span class=hljs-keyword>return</span> DimensionToken, l.r.Shift()
    } <span class=hljs-keyword>else</span> <span class=hljs-keyword>if</span> l.r.Peek(<span class=hljs-number>0</span>) == <span class=hljs-string>'%'</span> {
        l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume '%'</span>
        <span class=hljs-keyword>return</span> PercentageToken, l.r.Shift()
    }

    <span class=hljs-keyword>return</span> NumberToken, l.r.Shift()
}</code></pre></li><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume_token.go#L18-L43 rel="external nofollow noreferrer"><code>consumeUnicodeRangeToken()</code></a></p><ul><li>有以下几种情况：<ul><li><code>U+0000FF</code>，<code>+</code> 后面可以跟 1 ~ 6 个 16 进制数字；</li><li><code>U+0000??</code>，<code>+</code> 后面先跟 16 进制数字再跟 <code>?</code>（通配符），总数不超过 6 个；</li><li><code>U+0001-0002</code>，<code>-</code> 两侧可以有 1 ~ 6 个 16 进制数字。</li></ul></li><li>这些情况需要各自分类讨论，最后产生一个 urange-token。</li></ul><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#urange</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeUnicodeRangeToken() (TokenType, []<span class=hljs-type>rune</span>) {
    <span class=hljs-comment>// range start</span>
    start_length_remaining := <span class=hljs-number>6</span>
    <span class=hljs-keyword>for</span> next := l.r.Peek(<span class=hljs-number>0</span>); start_length_remaining &gt; <span class=hljs-number>0</span> &amp;&amp; next != EOF &amp;&amp; isASCIIHexDigit(next); next = l.r.Peek(<span class=hljs-number>0</span>) {
        l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the hex digit</span>
        start_length_remaining--
    }

    <span class=hljs-keyword>if</span> start_length_remaining &gt; <span class=hljs-number>0</span> &amp;&amp; l.r.Peek(<span class=hljs-number>0</span>) == <span class=hljs-string>'?'</span> { <span class=hljs-comment>// wildcard range</span>
        <span class=hljs-keyword>for</span> start_length_remaining &gt; <span class=hljs-number>0</span> &amp;&amp; l.r.Peek(<span class=hljs-number>0</span>) == <span class=hljs-string>'?'</span> {
            l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the '?'</span>
            start_length_remaining--
        }
    } <span class=hljs-keyword>else</span> <span class=hljs-keyword>if</span> l.r.Peek(<span class=hljs-number>0</span>) == <span class=hljs-string>'-'</span> &amp;&amp; isASCIIHexDigit(l.r.Peek(<span class=hljs-number>1</span>)) { <span class=hljs-comment>// range end</span>
        l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the '-'</span>

        end_length_remaining := <span class=hljs-number>6</span>
        <span class=hljs-keyword>for</span> next := l.r.Peek(<span class=hljs-number>0</span>); end_length_remaining &gt; <span class=hljs-number>0</span> &amp;&amp; next != EOF &amp;&amp; isASCIIHexDigit(next); next = l.r.Peek(<span class=hljs-number>0</span>) {
            l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the hex digit</span>
            end_length_remaining--
        }
    }

    <span class=hljs-keyword>return</span> UnicodeRangeToken, l.r.Shift()
}</code></pre></li><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume_token.go#L47-L68 rel="external nofollow noreferrer"><code>consumeIdentLikeToken()</code></a></p><ul><li>先 consume 一个合法的 name；</li><li>然后判断是否为一个函数的开始，如果是，再判断是否是 url-token，转入特定的解析流程。<ul><li>需要额外注意的是，如果 url 函数的参数是使用单 / 双引号包裹的字符串，那么按照普通函数参数解析即可。</li></ul></li></ul><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-ident-like-token</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeIdentLikeToken() (TokenType, []<span class=hljs-type>rune</span>) {
    l.consumeName()

    <span class=hljs-keyword>if</span> l.r.Peek(<span class=hljs-number>0</span>) == <span class=hljs-string>'('</span> {
        l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the opening parenthesis</span>
        <span class=hljs-keyword>if</span> equalIgnoringASCIICase(l.r.Current(), urlRunes) {
            <span class=hljs-comment>// The spec is slightly different so as to avoid dropping whitespace</span>
            <span class=hljs-comment>// tokens, but they wouldn't be used and this is easier.</span>
            l.consumeWhitespace()

            next := l.r.Peek(<span class=hljs-number>0</span>)
            <span class=hljs-keyword>if</span> next != <span class=hljs-string>'"'</span> &amp;&amp; next != <span class=hljs-string>'\''</span> {
                <span class=hljs-keyword>return</span> l.consumeURLToken()
            }
        }

        <span class=hljs-keyword>return</span> FunctionToken, l.r.Shift()
    }

    <span class=hljs-keyword>return</span> IdentToken, l.r.Shift()
}</code></pre><p>注意这里的实现其实会在含转义的 URL-token 上出现问题，后续通过修改 consumeName 函数的实现，通过返回值判断解决了此问题。</p></li><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume_token.go#L70-L112 rel="external nofollow noreferrer"><code>consumeStringToken()</code></a></p><ul><li>简而言之，就是从开始的引号的位置一直匹配到相对应的结束引号位置或者文件末尾；</li><li>特别地，如果遇到没有转义的换行，那么此时就需要作为 bad-string-token 返回了。</li></ul><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-string-token</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeStringToken() (TokenType, []<span class=hljs-type>rune</span>) {
    until := l.r.Peek(<span class=hljs-number>0</span>) <span class=hljs-comment>// the opening quote, already checked valid by the caller</span>
    l.r.Move(<span class=hljs-number>1</span>)

    <span class=hljs-keyword>for</span> {
        next := l.r.Peek(<span class=hljs-number>0</span>)

        <span class=hljs-keyword>if</span> next == until {
            l.r.Move(<span class=hljs-number>1</span>)
            <span class=hljs-keyword>return</span> StringToken, l.r.Shift()
        }

        <span class=hljs-keyword>if</span> next == EOF {
            <span class=hljs-keyword>return</span> StringToken, l.r.Shift()
        }

        <span class=hljs-keyword>if</span> isCSSNewline(next) {
            <span class=hljs-keyword>return</span> BadStringToken, l.r.Shift()
        }

        <span class=hljs-keyword>if</span> next == <span class=hljs-string>'\\'</span> {
            next_next := l.r.Peek(<span class=hljs-number>1</span>)

            <span class=hljs-keyword>if</span> next_next == EOF {
                l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the backslash</span>
                <span class=hljs-keyword>continue</span>
            }

            <span class=hljs-keyword>if</span> isCSSNewline(next_next) {
                l.r.Move(<span class=hljs-number>1</span>)
                l.consumeSingleWhitespace()
            } <span class=hljs-keyword>else</span> <span class=hljs-keyword>if</span> twoCharsAreValidEscape(next, next_next) {
                l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the backslash</span>
                l.consumeEscape()
            } <span class=hljs-keyword>else</span> {
                l.r.Move(<span class=hljs-number>1</span>)
            }
        } <span class=hljs-keyword>else</span> {
            l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the current rune</span>
        }
    }
}</code></pre></li><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume_token.go#L114-L164 rel="external nofollow noreferrer"><code>consumeURLToken()</code></a></p><ul><li>需要按照规范特别注意 bad-url-token 的情况。</li><li>但此处的实现和规范不同，在 <code>consumeIdentLikeToken()</code> 中我们把 URL 的前导空格全部 consume 掉了，但如果遇到使用引号包裹的 URL 时，这段空格理应单独作为一个 whitespace-token，不过无伤大雅，这样解析也可以，不影响后续的 parse 流程。</li></ul><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-url-token</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeURLToken() (TokenType, []<span class=hljs-type>rune</span>) {
    <span class=hljs-keyword>for</span> {
        next := l.r.Peek(<span class=hljs-number>0</span>)

        <span class=hljs-keyword>if</span> next == <span class=hljs-string>')'</span> {
            l.r.Move(<span class=hljs-number>1</span>)
            <span class=hljs-keyword>return</span> UrlToken, l.r.Shift()
        }

        <span class=hljs-keyword>if</span> next == EOF {
            <span class=hljs-keyword>return</span> UrlToken, l.r.Shift()
        }

        <span class=hljs-keyword>if</span> isHTMLWhitespace(next) {
            l.consumeWhitespace()

            next_next := l.r.Peek(<span class=hljs-number>0</span>)
            <span class=hljs-keyword>if</span> next_next == <span class=hljs-string>')'</span> {
                l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the closing parenthesis</span>
                <span class=hljs-keyword>return</span> UrlToken, l.r.Shift()
            }
            <span class=hljs-keyword>if</span> next_next == EOF {
                <span class=hljs-keyword>return</span> UrlToken, l.r.Shift()
            }

            <span class=hljs-comment>// If the next character is not a closing parenthesis, there's an error and we should mark it as a bad URL token.</span>
            <span class=hljs-keyword>break</span>
        }

        <span class=hljs-keyword>if</span> next == <span class=hljs-string>'"'</span> || next == <span class=hljs-string>'\''</span> || isNonPrintableCodePoint(next) {
            l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the invalid character</span>
            <span class=hljs-keyword>break</span>
        }

        <span class=hljs-keyword>if</span> next == <span class=hljs-string>'\\'</span> {
            <span class=hljs-keyword>if</span> twoCharsAreValidEscape(next, l.r.Peek(<span class=hljs-number>1</span>)) {
                l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the backslash</span>
                l.consumeEscape()
                <span class=hljs-keyword>continue</span>
            } <span class=hljs-keyword>else</span> {
                <span class=hljs-keyword>break</span>
            }
        }

        l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the current rune</span>
    }

    l.consumeBadUrlRemnants()
    <span class=hljs-keyword>return</span> BadUrlToken, l.r.Shift()
}</code></pre></li></ul><h3 id=特定类型字符片段解析>特定类型字符片段解析</h3><p>一共有以下几个片段解析的函数：</p><ul><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L3-L19 rel="external nofollow noreferrer"><code>consumeUntilCommentEnd()</code></a>：一直读取到注释结束。</p><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-comment</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeUntilCommentEnd() {
    <span class=hljs-keyword>for</span> {
        next := l.r.Peek(<span class=hljs-number>0</span>)

        <span class=hljs-keyword>if</span> next == EOF {
            <span class=hljs-keyword>break</span>
        }

        <span class=hljs-keyword>if</span> next == <span class=hljs-string>'*'</span> &amp;&amp; l.r.Peek(<span class=hljs-number>1</span>) == <span class=hljs-string>'/'</span> {
            l.r.Move(<span class=hljs-number>2</span>) <span class=hljs-comment>// consume '*/'</span>
            <span class=hljs-keyword>return</span>
        }

        l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the current rune</span>
    }
}</code></pre></li><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L21-L42 rel="external nofollow noreferrer"><code>consumeEscape()</code></a>：解析一个转义字符。</p><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-escaped-code-point</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeEscape() <span class=hljs-type>rune</span> {
    <span class=hljs-keyword>var</span> res <span class=hljs-type>rune</span> = <span class=hljs-number>0</span>

    next := l.r.Peek(<span class=hljs-number>0</span>)

    <span class=hljs-keyword>if</span> isASCIIHexDigit(next) {
        l.r.Move(<span class=hljs-number>1</span>)
        res = hexDigitToValue(next)

        <span class=hljs-keyword>for</span> i := <span class=hljs-number>1</span>; i &lt; <span class=hljs-number>6</span>; i++ {
            c := l.r.Peek(<span class=hljs-number>0</span>)
            <span class=hljs-keyword>if</span> isASCIIHexDigit(c) {
                l.r.Move(<span class=hljs-number>1</span>)
                res = res*<span class=hljs-number>16</span> + hexDigitToValue(c)
            } <span class=hljs-keyword>else</span> {
                <span class=hljs-keyword>break</span>
            }
        }

        <span class=hljs-keyword>if</span> !isValidCodePoint(res) {
            res = <span class=hljs-string>'\uFFFD'</span> <span class=hljs-comment>// U+FFFD REPLACEMENT CHARACTER</span>
        }

        <span class=hljs-comment>// If the next input code point is whitespace, consume it as well.</span>
        l.consumeSingleWhitespace()
    } <span class=hljs-keyword>else</span> <span class=hljs-keyword>if</span> next != EOF {
        l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the escape character</span>
        res = next
    } <span class=hljs-keyword>else</span> {
        res = <span class=hljs-string>'\uFFFD'</span> <span class=hljs-comment>// U+FFFD REPLACEMENT CHARACTER for EOF</span>
    }

    <span class=hljs-keyword>return</span> res
}</code></pre></li><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L44-L58 rel="external nofollow noreferrer"><code>consumeName()</code></a>：读取一个 name。</p><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-name</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeName() {
    <span class=hljs-keyword>for</span> {
        next := l.r.Peek(<span class=hljs-number>0</span>)

        <span class=hljs-keyword>if</span> isNameCodePoint(next) {
            l.r.Move(<span class=hljs-number>1</span>)
        } <span class=hljs-keyword>else</span> <span class=hljs-keyword>if</span> twoCharsAreValidEscape(next, l.r.Peek(<span class=hljs-number>1</span>)) {
            l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the backslash</span>
            l.consumeEscape()
        } <span class=hljs-keyword>else</span> {
            <span class=hljs-keyword>break</span>
        }
    }
}</code></pre></li><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L60-L92 rel="external nofollow noreferrer"><code>consumeNumber()</code></a>：读取一个数字。需要特别注意对科学计数法的处理，以及与调用侧配合正确解析 <code>.7</code> <code>+.7</code> 等 case。</p><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-number</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeNumber() {
    next := l.r.Peek(<span class=hljs-number>0</span>)

    <span class=hljs-comment>// If the next rune is '+' or '-', consume it as part of the number.</span>
    <span class=hljs-keyword>if</span> next == <span class=hljs-string>'+'</span> || next == <span class=hljs-string>'-'</span> {
        l.r.Move(<span class=hljs-number>1</span>)
    }

    <span class=hljs-comment>// consume the integer part of the number</span>
    l.r.MoveWhilePredicate(isASCIIDigit)

    <span class=hljs-comment>// float</span>
    next = l.r.Peek(<span class=hljs-number>0</span>)
    <span class=hljs-keyword>if</span> next == <span class=hljs-string>'.'</span> &amp;&amp; isASCIIDigit(l.r.Peek(<span class=hljs-number>1</span>)) {
        l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the '.'</span>
        l.r.MoveWhilePredicate(isASCIIDigit)
    }

    <span class=hljs-comment>// scientific notation</span>
    next = l.r.Peek(<span class=hljs-number>0</span>)
    <span class=hljs-keyword>if</span> next == <span class=hljs-string>'e'</span> || next == <span class=hljs-string>'E'</span> {
        next_next := l.r.Peek(<span class=hljs-number>1</span>)

        <span class=hljs-keyword>if</span> isASCIIDigit(next_next) {
            l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume 'e' or 'E'</span>
            l.r.MoveWhilePredicate(isASCIIDigit)
        } <span class=hljs-keyword>else</span> <span class=hljs-keyword>if</span> (next_next == <span class=hljs-string>'+'</span> || next_next == <span class=hljs-string>'-'</span>) &amp;&amp; isASCIIDigit(l.r.Peek(<span class=hljs-number>2</span>)) {
            l.r.Move(<span class=hljs-number>2</span>) <span class=hljs-comment>// consume 'e' or 'E' and the sign</span>
            l.r.MoveWhilePredicate(isASCIIDigit)
        }
    }
}</code></pre></li><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L94-L101 rel="external nofollow noreferrer"><code>consumeSingleWhitespace()</code></a>：读取一个空格。</p><pre><code class="hljs go"><span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeSingleWhitespace() {
    next := l.r.Peek(<span class=hljs-number>0</span>)
    <span class=hljs-keyword>if</span> next == <span class=hljs-string>'\r'</span> &amp;&amp; l.r.Peek(<span class=hljs-number>1</span>) == <span class=hljs-string>'\n'</span> {
        l.r.Move(<span class=hljs-number>2</span>) <span class=hljs-comment>// consume CRLF</span>
    } <span class=hljs-keyword>else</span> <span class=hljs-keyword>if</span> isHTMLWhitespace(next) {
        l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the whitespace character</span>
    }
}</code></pre></li><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L103-L115 rel="external nofollow noreferrer"><code>consumeWhitespace()</code></a>：读取多个空格。</p><pre><code class="hljs go"><span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeWhitespace() {
    <span class=hljs-keyword>for</span> {
        next := l.r.Peek(<span class=hljs-number>0</span>)

        <span class=hljs-keyword>if</span> isHTMLWhitespace(next) {
            l.consumeSingleWhitespace()
        } <span class=hljs-keyword>else</span> <span class=hljs-keyword>if</span> next == EOF {
            <span class=hljs-keyword>return</span>
        } <span class=hljs-keyword>else</span> {
            <span class=hljs-keyword>break</span>
        }
    }
}</code></pre></li><li><p><a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L117-L138 rel="external nofollow noreferrer"><code>consumeBadUrlRemnants()</code></a>：读取 bad-url-token 的剩余部分。</p><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-the-remnants-of-a-bad-url</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> consumeBadUrlRemnants() {
    <span class=hljs-keyword>for</span> {
        next := l.r.Peek(<span class=hljs-number>0</span>)

        <span class=hljs-keyword>if</span> next == <span class=hljs-string>')'</span> {
            l.r.Move(<span class=hljs-number>1</span>)
            <span class=hljs-keyword>return</span>
        }
        <span class=hljs-keyword>if</span> next == EOF {
            <span class=hljs-keyword>return</span>
        }

        <span class=hljs-keyword>if</span> twoCharsAreValidEscape(next, l.r.Peek(<span class=hljs-number>1</span>)) {
            l.r.Move(<span class=hljs-number>1</span>) <span class=hljs-comment>// consume the backslash</span>
            l.consumeEscape()
            <span class=hljs-keyword>continue</span>
        }

        l.r.Move(<span class=hljs-number>1</span>)
    }
}</code></pre></li></ul><h3 id=identifier-和-number-的鉴别逻辑>Identifier 和 Number 的鉴别逻辑</h3><p>对于 identifier，我们根据以下标准判断接下来的字符是否可能开始一个 identifier 的序列：</p><ul><li>第一位是 NameStartCodePoint（以英文字母、下划线或非 ASCII 字母开始）；或</li><li>第一位和第二位组合起来可以开始一段转义序列；或</li><li>以 <code>-</code> 开始的 identifier（再走一遍上面两点的识别流程，同时注意 <code>--</code> 的情况）。</li></ul><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#would-start-an-identifier</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> nextCharsAreIdentifier() <span class=hljs-type>bool</span> {
    first := l.r.Peek(<span class=hljs-number>0</span>)

    <span class=hljs-keyword>if</span> isNameStartCodePoint(first) {
        <span class=hljs-keyword>return</span> <span class=hljs-literal>true</span>
    }

    second := l.r.Peek(<span class=hljs-number>1</span>)

    <span class=hljs-keyword>if</span> twoCharsAreValidEscape(first, second) {
        <span class=hljs-keyword>return</span> <span class=hljs-literal>true</span>
    }

    <span class=hljs-keyword>if</span> first == <span class=hljs-string>'-'</span> {
        <span class=hljs-keyword>return</span> isNameStartCodePoint(second) || second == <span class=hljs-string>'-'</span> ||
            twoCharsAreValidEscape(second, l.r.Peek(<span class=hljs-number>2</span>))
    }

    <span class=hljs-keyword>return</span> <span class=hljs-literal>false</span>
}</code></pre><p>对于 number，当符合以下条件的时候可以开始一个 number 的序列：</p><ul><li>第一位是数字；</li><li>第一位是正负号，第二位是数字；</li><li>第一位是正负号，第二位是小数点，第三位是数字；</li><li>第一位是小数点，第二位是数字。</li></ul><pre><code class="hljs go"><span class=hljs-comment>// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#starts-with-a-number</span>
<span class=hljs-function><span class=hljs-keyword>func</span> <span class=hljs-params>(l *Lexer)</span></span> nextCharsAreNumber() <span class=hljs-type>bool</span> {
    first := l.r.Peek(<span class=hljs-number>0</span>)

    <span class=hljs-keyword>if</span> isASCIIDigit(first) {
        <span class=hljs-keyword>return</span> <span class=hljs-literal>true</span>
    }

    second := l.r.Peek(<span class=hljs-number>1</span>)

    <span class=hljs-keyword>if</span> first == <span class=hljs-string>'+'</span> || first == <span class=hljs-string>'-'</span> {
        <span class=hljs-keyword>if</span> isASCIIDigit(second) {
            <span class=hljs-keyword>return</span> <span class=hljs-literal>true</span>
        }

        <span class=hljs-keyword>if</span> second == <span class=hljs-string>'.'</span> {
            third := l.r.Peek(<span class=hljs-number>2</span>)

            <span class=hljs-keyword>if</span> isASCIIDigit(third) {
                <span class=hljs-keyword>return</span> <span class=hljs-literal>true</span>
            }
        }
    }

    <span class=hljs-keyword>if</span> first == <span class=hljs-string>'.'</span> {
        <span class=hljs-keyword>return</span> isASCIIDigit(second)
    }

    <span class=hljs-keyword>return</span> <span class=hljs-literal>false</span>
}</code></pre><h3 id=小结>小结</h3><p>让我们来总结一下 lexer 工作流程：在 lexer 读取到某个 token 的起始点的时候，lexer 预读起始的几个字符，然后辨别 token 的类型。对于大致分类好的 token，根据其更具体的特征预读并消耗掉对应的字符，直到这个 token 结束。</p><p>大致的类型辨别是通过 <code>Next()</code> 函数中的那个巨大的 switch-case 语句来完成的。而对于精细的 token 类型的判断，则是 case 中的语句和 <code>consume_token.go</code> 定义的一系列函数来共同完成的。至于 token 内部的字符段的解析，则是 <code>consume.go</code> 中的一系列函数完成的。由此组合，整个 token 的解析过程得以良好运转。</p><p>除了文中提到的相关方法以外，在 <a href=https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/util.go rel="external nofollow noreferrer"><code>util.go</code></a> 中还有一系列的工具函数：</p><ul><li><code>func isASCII(c rune) bool</code></li><li><code>func isASCIIAlpha(c rune) bool</code></li><li><code>func isASCIIDigit(c rune) bool</code></li><li><code>func isASCIIHexDigit(c rune) bool</code></li><li><code>func isCSSNewline(c rune) bool</code></li><li><code>func isNameStartCodePoint(r rune) bool</code></li><li><code>func isNameCodePoint(r rune) bool</code></li><li><code>func isNonPrintableCodePoint(r rune) bool</code></li><li><code>func twoCharsAreValidEscape(first, second rune) bool</code></li><li><code>func isHTMLSpecialWhitespace(c rune) bool</code></li><li><code>func isHTMLWhitespace(c rune) bool</code></li></ul><p>这些函数的作用可以很容易地由它们的名字得知，故此处不再赘述。</p><h2 id=测试>测试</h2><p>为了验证 lexer 的实现正确性，我们引入了 <a href=https://github.com/romainmenke/css-tokenizer-tests/tree/5e2112b59e728205a870ff130987e5204c425f59/tests rel="external nofollow noreferrer">romainmenke/css-tokenizer-tests</a> 的测试用例来对 lexer 进行测试。具体的测试流程可以参考 <a href=https://github.com/renbaoshuo/go-css-lexer/blob/master/lexer_test.go rel="external nofollow noreferrer"><code>lexer_test.go</code></a> 中的实现。</p><p>根据测试结果来看，出现的问题主要集中在与转义字符相关的处理，对于大部分情况已经能够正常解析。截止编写本文之时，测试通过率为 96.53% (167/173)，个人认为已经处于可用水平。</p><h2 id=后记>后记</h2><p>文中所述的 lexer 的具体实现已经开源在 <a href=https://github.com/renbaoshuo/go-css-lexer rel="external nofollow noreferrer">renbaoshuo/go-css-lexer</a>，欢迎大家 Star！</p><p>搓这个 lexer 花了半个周末的时间，修修补补又消耗了一些时间。也算是在工作之余充实自己的大脑了。后续还可能会针对预读相关的内存访问进行优化（不知道读者有没有发现最多会预读三个字符），以提升处理效率。</p><p>文章题图由 Gemini 2.5 Pro Imagen 生成。</p></section><div class="E Ge w x He z ud vd"><div class=d>实现一个 CSS 词法分析器（Lexer）</div><div><a class="pb Ie kd Mb" href=/post/css-lexer/ >https://blog.baoshuo.ren/post/css-lexer/</a></div><div class="m Je J"><div class="m kb qb Rd sb"><div class=Ke>本文作者</div><div><a class="Lb nb Mb" href=https://baoshuo.ren target=_blank>宝硕</a></div></div><div class="m kb qb Rd sb"><div class=Ke>发布于</div><time datetime=2025-08-05T15:18:52.000Z>2025-08-05</time></div><div class="m kb qb Rd sb"><div class=Ke>更新于</div><time>2026-01-21</time></div><div class="m kb qb Rd sb"><div class=Ke>版权协议</div><div><a class="Lb nb Mb" href=https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode.zh-Hans target=_blank rel="license noopener noreferrer">CC BY-NC-SA 4.0</a></div></div></div><div class=Ke>转载或引用本文时请遵守许可协议，注明出处、不得用于商业用途！</div><i class="a h Nf Zg ah bh ch dh eh fh gh hh ih R f S T jh kh lh mh Pf Sf nh oh ph qh Tf Uf Vf Wf rh sh th uh vh wh xh yh zh Gg Ig Ah Bh Ch Dh Eh Fh Gh Hh Ih Jh Kh Lh Mh Nh Oh Ph Qh"></i></div><div class="Jc F x H z"><a class="pb nb Fe Mb" href=/tags/CSS/ ># <!-- -->CSS</a><a class="pb nb Fe Mb" href=/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/ ># <!-- -->编译原理</a></div></article><div class="Qb Rb Sb Tb Ub Vb Wb Xb F x H z Zb ac J bc sb cc Bc Jc"><div>喜欢这篇文章？为什么不考虑打赏一下作者呢？</div><a class="Vc ld te qd rd sd td nb ue zc ve ub a Cc" href=https://afdian.net/@baoshuo target=_blank rel="noopener noreferrer">爱发电</a></div><div class="m Zb ac J bc sb cc we xe"><div class="m ye ze Ae De Ee"><a class="m o Kb nd Nb y Ob" href=/post/goodbye-2024/ >向着璀璨的未来进发 —— 我的 2024 年度总结<i class="Ug Mf Nf E a Lf Kf Pf Sf Tg Vg Wg Xg Yg Tf Uf Vf Wf dg bg Rf Qf"></i></a></div></div><div class="Qb Rb Sb Tb Ub Vb Wb Xb F x H z Zb ac J bc sb cc"></div></main></div><div class="mc Nc Oc Pc"><div class="Lb Ic Qc Rc Sc Tc Uc Rb Sb Tb Ub Vc Wc Xc Xb"><i class="a E Kf Lf Mf Nf Of Pf Qf Rf Sf Xf Tf eg fg gg"></i></div><a class="Lb Ic Qc Rc Sc Tc Uc Rb Sb Tb Ub Vc Wc Xc Xb" href=#><i class="a E Kf Lf Mf Nf Of Pf Qf Rf Sf Tf Uf Vf Wf Xf Yf Zf ag bg cg dg"></i></a></div><footer class="yc zc Ac ub pb Qb Bc Cc Xb Dc Ec Fc Gc Hc"><div class="Ic Jc Kc Lc"><div>Copyright © 2019 - <!-- -->2026<!-- --> <a class="Lb Mc Mb Pb" href=/ >宝硕博客</a><span class="s Kd u Ld Md"></span><a class="Lb Mc Mb Pb" href=https://beian.miit.gov.cn target=_blank rel="noopener noreferer nofollow">冀ICP备15024669号-3</a></div><div>Powered by<!-- --> <a class="mb Mc Mb" href=https://nextjs.org target=_blank rel="noopener noreferer nofollow">Next.js</a> &amp; <a class="mb Mc Mb" href=https://hexo.io target=_blank rel="noopener noreferer nofollow">Hexo</a><span class="s Kd u Ld Md"></span>Designed by<!-- --> <a class="mb Mc Mb" href=https://baoshuo.ren target=_blank>Baoshuo</a></div></div></footer></div><script id=__NEXT_DATA__ type=application/json>{"props":{"pageProps":{"title":"实现一个 CSS 词法分析器（Lexer） - 宝硕博客","post":{"title":"实现一个 CSS 词法分析器（Lexer）","excerpt":"最近在实习的时候，遇到了一些需求，需要自己去实现 CSS 的解析、（伪）渲染流程。以之为契机，我学习了一下编译相关的知识，其中的第一环就是 Lexer。","content":[["$","p",{},["最近在实习的时候，遇到了一些需求，需要自己去实现 CSS 的解析、（伪）渲染流程。以之为契机，我学习了一下编译相关的知识，其中的第一环就是 Lexer。"]],["$","span",{"id":"more"},[]],["$","p",{},["本文中的代码均使用 Go 实现，成果已经作为 Go 库 ",["$","a",{"href":"https://pkg.go.dev/go.baoshuo.dev/csslexer","rel":"external nofollow noreferrer"},[["$","code",{},["go.baoshuo.dev/csslexer"]]]]," 发布。"]],["$","ul",{},[["$","li",{},["GitHub 仓库：",["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer","rel":"external nofollow noreferrer"},["renbaoshuo/go-css-lexer"]]]],["$","li",{},["实现标准：",["$","a",{"href":"https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/","rel":"external nofollow noreferrer"},["CSS Syntax Module Level 3 (W3C Candidate Recommendation Draft; 24 December 2021)"]]]]]],["$","p",{},[["$","em",{},["建议在阅读本文前对 CSS 标准内容有一定理解。"]]]],["$","h2",{"id":"词法分析"},["词法分析"]],["$","blockquote",{},[["$","p",{},["词法分析（lexical analysis）是计算机科学中将字符序列转换为记号（token，也有译为标记或词元）序列的过程。进行词法分析的程序或者函数叫作词法分析器（lexical analyzer，简称 lexer），也叫扫描器（scanner）。词法分析器一般以函数的形式存在，供语法分析器调用。"]],["$","p",{},[["$","cite",{},["——维基百科"]]]]]],["$","p",{},["词法分析是编译中的第一个步骤。它读入组成源码的字符流，并将他们组织成一个个的词素（lexeme）。有了词素以后，识别并标注它的类型，就可以生成一个 ",["$","code",{},["\u003ctoken-name, attribute-value\u003e"]]," 形式的词法单元（token）。这个单元会被传送给下一个步骤 —— 语法分析 —— 进行后续的处理。"]],["$","p",{},["在进行词法分析之前，首先要设定好到底有多少种 token 类型，然后再确定每个 token 类型的判断条件和解析方式。"]],["$","h2",{"id":"token-的分类"},["Token 的分类"]],["$","p",{},["由 CSS Syntax Module Level 3 中的 ",["$","a",{"href":"https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#tokenization","rel":"external nofollow noreferrer"},["4. Tokenization"]]," 一节可以得到 CSS 的 token 有以下几种类型："]],["$","pre",{},[["$","code",{"class":"hljs text"},["\u003cident-token\u003e\n\u003cfunction-token\u003e\n\u003cat-keyword-token\u003e\n\u003chash-token\u003e\n\u003cstring-token\u003e\n\u003cbad-string-token\u003e\n\u003curl-token\u003e\n\u003cbad-url-token\u003e\n\u003cdelim-token\u003e\n\u003cnumber-token\u003e\n\u003cpercentage-token\u003e\n\u003cdimension-token\u003e\n\u003cwhitespace-token\u003e\n\u003cCDO-token\u003e\n\u003cCDC-token\u003e\n\u003ccolon-token\u003e\n\u003csemicolon-token\u003e\n\u003ccomma-token\u003e\n\u003c[-token\u003e\n\u003c]-token\u003e\n\u003c(-token\u003e\n\u003c)-token\u003e\n\u003c{-token\u003e\n\u003c}-token\u003e"]]]],["$","p",{},["为了解析方便，我们又在标准的 token 类型外拓展了几个 token 类型，得到了下面的 token 表："]],["$","pre",{},[["$","code",{"class":"hljs text"},["\u003cident-token\u003e         IdentToken\n\u003cfunction-token\u003e      FunctionToken            foo()\n\u003cat-keyword-token\u003e    AtKeywordToken           @foo\n\u003chash-token\u003e          HashToken                #foo\n\u003cstring-token\u003e        StringToken\n\u003cbad-string-token\u003e    BadStringToken\n\u003curl-token\u003e           UrlToken                 url()\n\u003cbad-url-token\u003e       BadUrlToken\n\u003cdelim-token\u003e         DelimiterToken\n\u003cnumber-token\u003e        NumberToken              3\n\u003cpercentage-token\u003e    PercentageToken          3%\n\u003cdimension-token\u003e     DimensionToken           3em\n\u003cwhitespace-token\u003e    WhitespaceToken\n\u003cCDO-token\u003e           CDOToken                 \u003c!--\n\u003cCDC-token\u003e           CDCToken                 --\u003e\n\u003ccolon-token\u003e         ColonToken               :\n\u003csemicolon-token\u003e     SemicolonToken           ;\n\u003ccomma-token\u003e         CommaToken               ,\n\u003c(-token\u003e             LeftParenthesisToken     (\n\u003c)-token\u003e             RightParenthesisToken    )\n\u003c[-token\u003e             LeftBracketToken         [\n\u003c]-token\u003e             RightBracketToken        ]\n\u003c{-token\u003e             LeftBraceToken           {\n\u003c}-token\u003e             RightBraceToken          }\n\u003cEOF-token\u003e           EOFToken\n\nCommentToken          /* ... */\nIncludeMatchToken     ~=\nDashMatchToken        |=\nPrefixMatchToken      ^=\nSuffixMatchToken      $=\nSubstringMatchToken   *=\nColumnToken           ||\nUnicodeRangeToken"]]]],["$","p",{},["于是乎，我们就有了词法分析的期望目标产物 —— 由这 33 种类型的 token 组成的 token 流。"]],["$","h2",{"id":"输入流"},["输入流"]],["$","blockquote",{},[["$","p",{},["工欲善其事，必先利其器。"]]]],["$","p",{},["在实现真正的词法分析流程以前，我们需要编写一套输入流来辅助我们完成读入的操作。"]],["$","p",{},["首先，我们给出输入流的定义："]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// Input represents a stream of runes read from a source."]],"\n",["$","span",{"class":"hljs-keyword"},["type"]]," Input ",["$","span",{"class":"hljs-keyword"},["struct"]]," {\n    runes []",["$","span",{"class":"hljs-type"},["rune"]]," ",["$","span",{"class":"hljs-comment"},["// The runes in the input stream."]],"\n    pos   ",["$","span",{"class":"hljs-type"},["int"]],"    ",["$","span",{"class":"hljs-comment"},["// The current position in the input stream."]],"\n    start ",["$","span",{"class":"hljs-type"},["int"]],"    ",["$","span",{"class":"hljs-comment"},["// The start position of the current token being read."]],"\n    err   ",["$","span",{"class":"hljs-type"},["error"]],"  ",["$","span",{"class":"hljs-comment"},["// Any error encountered while reading the input."]],"\n}"]]]],["$","p",{},["这个结构封装了对一个 rune 切片的访问，并维护了当前扫描的位置（pos）和当前正在扫描的 token 的起始位置（start）。"]],["$","p",{},["需要注意的是，我们使用 ",["$","code",{},["rune"]]," 而不是 ",["$","code",{},["byte"]]," 来存储内容，这样做的原因是为了便于处理代码中包含的 Emoji 等 Unicode 字符。"]],["$","p",{},["为了使用方便，这个输入流可以从 ",["$","code",{},["string"]],"、",["$","code",{},["[]rune"]],"、",["$","code",{},["[]byte"]]," 和 ",["$","code",{},["io.Reader"]]," 初始化。实现细节可以查看仓库中的 ",["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/master/input.go","rel":"external nofollow noreferrer"},[["$","code",{},["input.go"]]]],"，各个函数签名如下："]],["$","ul",{},[["$","li",{},[["$","code",{},["NewInput(input string) *Input"]]]],["$","li",{},[["$","code",{},["NewInputRunes(runes []rune) *Input"]]]],["$","li",{},[["$","code",{},["NewInputBytes(input []byte) *Input"]]]],["$","li",{},[["$","code",{},["NewInputReader(r io.Reader) *Input"]]]]]],["$","p",{},["接下来，我们需要设计一系列合理的方法，使得这个输入流的使用能够在满足我们的实际需求的同时，还保持简洁的风格。"]],["$","p",{},["在 4.2 节的一系列定义中，通过观察不难发现，在解析过程中会不断地出现 consume 和 reconsume 的操作，也就是说，在输入流的末尾会不断地进行 pop_back 和 push_back 的操作。那么我们可以将这些操作转化为「预读」和「后移指针」的操作，以此来减少频繁在流末尾进行的弹出和插入操作。"]],["$","p",{},["于是，我们就有了以下两个方法："]],["$","ul",{},[["$","li",{},[["$","p",{},[["$","code",{},["func (z *Input) Peek(n int) rune"]]]],["$","p",{},["预读输入流中 ",["$","code",{},["pos+n"]]," 位置的字符。"]]]],["$","li",{},[["$","p",{},[["$","code",{},["func (z *Input) Move(n int)"]]]],["$","p",{},["将当前输入流的指针后移 ",["$","code",{},["n"]]," 位。"]]]]]],["$","p",{},["经过阅读规范以后，不难发现一个 token 可以由几个不同类别的字符序列组成，比如 ",["$","code",{},["16px"]]," 就是一个 ",["$","code",{},["16"]]," (number sequence) 和一个 ",["$","code",{},["px"]]," (ident sequence) 共同组成的 dimension-token。所以我们在解析一个 token 的时候可能会调用多个解析函数，那么就需要在 token 级别做一个固定的输出模式。"]],["$","p",{},["于是，我们定义 ",["$","code",{},["func (z *Input) Shift() []rune"]]," 来弹出当前 token，并更新 ",["$","code",{},["Input"]]," 实例中的 ",["$","code",{},["start"]]," 值，以开始下一 token 的解析。"]],["$","p",{},["不过后续在解析 url-token 的时候遇到了需要读取当前已经 consume 的内容的情况，于是将 ",["$","code",{},["Shift"]]," 方法拆分成了 ",["$","code",{},["Current"]]," 和 ",["$","code",{},["Shift"]]," 两个不同的方法，以便使用。"]],["$","p",{},["除此以外，在解析的时候还有需要在满足某一特定条件下一直 consume 的能力需求，因此又设计了较为通用的 ",["$","code",{},["func (z *Input) MoveWhilePredicate(pred func(rune) bool)"]]," 方法，来实现这一能力。"]],["$","p",{},["加上错误处理逻辑以后，整个 ",["$","code",{},["Input"]]," 的方法如下："]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(z *Input)"]]]]," PeekErr(pos ",["$","span",{"class":"hljs-type"},["int"]],") ",["$","span",{"class":"hljs-type"},["error"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(z *Input)"]]]]," Err() ",["$","span",{"class":"hljs-type"},["error"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(z *Input)"]]]]," Peek(n ",["$","span",{"class":"hljs-type"},["int"]],") ",["$","span",{"class":"hljs-type"},["rune"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(z *Input)"]]]]," Move(n ",["$","span",{"class":"hljs-type"},["int"]],")\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(z *Input)"]]]]," Current() []",["$","span",{"class":"hljs-type"},["rune"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(z *Input)"]]]]," Shift() []",["$","span",{"class":"hljs-type"},["rune"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(z *Input)"]]]]," MoveWhilePredicate(pred ",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]],["$","span",{"class":"hljs-params"},["(",["$","span",{"class":"hljs-type"},["rune"]],")"]]]]," ",["$","span",{"class":"hljs-type"},["bool"]],")"]]]],["$","p",{},["接下来，我们就可以正式开始 lexer 的编写了。"]],["$","h2",{"id":"词法分析器"},["词法分析器"]],["$","p",{},["其实 Lexer 的方法框架设计就相对简单了，下面直接给出定义："]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-keyword"},["type"]]," Lexer ",["$","span",{"class":"hljs-keyword"},["struct"]]," {\n    r *Input ",["$","span",{"class":"hljs-comment"},["// The input stream of runes to be lexed."]],"\n}\n\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," Err() ",["$","span",{"class":"hljs-type"},["error"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," Next() (TokenType, []",["$","span",{"class":"hljs-type"},["rune"]],")"]]]],["$","p",{},["在 ",["$","code",{},["Next"]]," 方法中有一个巨大的 switch-case 语句，这里面包含了 ",["$","a",{"href":"https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-token","rel":"external nofollow noreferrer"},["4.3.1. Consume a token"]]," 中所描述的所有在 token 开始时的情形。我们将会根据一个 token 开始的几个字符（小于等于 3 个）来确定这个 token 的后续部分应该如何解析。"]],["$","h3",{"id":"token-开始处的分类讨论"},["Token 开始处的分类讨论"]],["$","p",{},["开始解析 token 的时候一定是在文件流的开头或者上一个 token 刚刚解析完毕的时候，那么此时我们只需要根据对应规则判断 token 类型即可。"]],["$","p",{},["首先预读 1 个字符，记为 ",["$","code",{},["next"]],"，然后对这个字符进行分类讨论。"]],["$","ul",{},[["$","li",{},[["$","p",{},[["$","code",{},["EOF"]],"：直接返回 EOF-token。"]]]],["$","li",{},[["$","p",{},[["$","code",{},["\\t"]],", ",["$","code",{},["\\n"]],", ",["$","code",{},["\\r"]],", ",["$","code",{},["\\f"]],", ",["$","code",{},[]],"：根据标准需要将此字符及后续的所有 whitespace 组合成一个 whitespace-token。"]]]],["$","li",{},[["$","p",{},[["$","code",{},["/"]],"：如果是 ",["$","code",{},["/*"]]," 则一直读取到 ",["$","code",{},["*/"]]," 或者 ",["$","code",{},["EOF"]]," 作为 comment-token。"]]]],["$","li",{},[["$","p",{},[["$","code",{},["'"]]," (单引号), ",["$","code",{},["\""]],"(双引号)：遇到这两种引号，会调用字符串解析函数 ",["$","code",{},["consumeStringToken()"]],"。该函数会持续读取字符，直到遇到与之匹配的结束引号。在此过程中，它会处理转义字符（如 ",["$","code",{},["\\\""]],"）。如果在中途遇到换行符或文件末尾，则会生成一个 bad-string-token，否则生成一个 string-token。"]]]],["$","li",{},[["$","p",{},[["$","code",{},["0"]]," ~ ",["$","code",{},["9"]]," 的数字字符：如果以数字开头，确定无疑是数字类型，调用数字解析函数 ",["$","code",{},["consumeNumericToken()"]],"。"]]]],["$","li",{},[["$","p",{},[["$","code",{},["("]],", ",["$","code",{},[")"]],", ",["$","code",{},["["]],", ",["$","code",{},["]"]],", ",["$","code",{},["{"]],", ",["$","code",{},["}"]],"：生成对应的括号字符。function-token 或者 url-token 的情况会在处理 ident-like 的时候另行考虑。"]]]],["$","li",{},[["$","p",{},[["$","code",{},["+"]],", ",["$","code",{},["."]],"：这两个字符，再加上 ",["$","code",{},["-"]],"，都比较特殊。不过 ",["$","code",{},["-"]]," 需要包含一些额外的判断，因此归属于另外一条规则处理。"]],["$","ul",{},[["$","li",{},["解析器会向后预读，通过 ",["$","code",{},["nextCharsAreNumber()"]]," 判断后续字符是否能构成一个合法的数字（例如 ",["$","code",{},["+1.5"]],", ",["$","code",{},[".5"]],"）。"]],["$","li",{},["如果可以，则调用 ",["$","code",{},["consumeNumericToken()"]]," 将其完整解析为一个 numeric-token。"]],["$","li",{},["如果不构成数字，则 ",["$","code",{},["+"]]," 和 ",["$","code",{},["."]]," 会被当作 delimiter-token。"]]]]]],["$","li",{},[["$","p",{},[["$","code",{},["-"]],"：除了像 ",["$","code",{},["+"]]," 一样判断是否有可能进入数字的处理逻辑以外，还需要考虑作为 ",["$","code",{},["--\u003e"]]," (CDC-token) 和 ident-like 的情况。如果都不是才会被当做 delimiter-token。"]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-keyword"},["if"]]," l.nextCharsAreNumber() {\n    ",["$","span",{"class":"hljs-keyword"},["return"]]," l.consumeNumericToken()\n}\n",["$","span",{"class":"hljs-keyword"},["if"]]," l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],") == ",["$","span",{"class":"hljs-string"},["'-'"]]," \u0026\u0026 l.r.Peek(",["$","span",{"class":"hljs-number"},["2"]],") == ",["$","span",{"class":"hljs-string"},["'\u003e'"]]," {\n    l.r.Move(",["$","span",{"class":"hljs-number"},["3"]],") ",["$","span",{"class":"hljs-comment"},["// consume \"--\u003e\""]],"\n    ",["$","span",{"class":"hljs-keyword"},["return"]]," CDCToken, l.r.Shift()\n}\n",["$","span",{"class":"hljs-keyword"},["if"]]," l.nextCharsAreIdentifier() {\n    ",["$","span",{"class":"hljs-keyword"},["return"]]," l.consumeIdentLikeToken()\n}\nl.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n",["$","span",{"class":"hljs-keyword"},["return"]]," DelimiterToken, l.r.Shift()"]]]]]],["$","li",{},[["$","p",{},[["$","code",{},["\u003c"]],"：如果能构成 ",["$","code",{},["\u003c!--"]],"，解析为一个 CDO-token，否则解析为 delimiter-token。"]]]],["$","li",{},[["$","p",{},[["$","code",{},["*"]],", ",["$","code",{},["^"]],", ",["$","code",{},["$"]],", ",["$","code",{},["|"]],", ",["$","code",{},["~"]],": 这些是属性选择器中的匹配符。"]],["$","ul",{},[["$","li",{},["如果它们后面紧跟 ",["$","code",{},["="]],"，则会组合成一个专有 token：",["$","ul",{},[["$","li",{},[["$","code",{},["*="]]," → substring-match-token"]],["$","li",{},[["$","code",{},["^="]]," → prefix-match-token"]],["$","li",{},[["$","code",{},["$="]]," → suffix-match-token"]],["$","li",{},[["$","code",{},["~="]]," → include-match-token"]],["$","li",{},[["$","code",{},["|="]]," → dash-match-token"]]]]]],["$","li",{},["特别地，对于 ",["$","code",{},["|"]],"，如果能够组成 ",["$","code",{},["||"]],"，则会成为 column-token。"]],["$","li",{},["如果没有，则单独作为 delimiter-token。"]]]]]],["$","li",{},[["$","p",{},[["$","code",{},["@"]],"：如果后续的字符能够组成一个 identifier，那么解析为 at-keyword-token，否则解析为 delimiter-token。"]]]],["$","li",{},[["$","p",{},[["$","code",{},[","]]," (逗号)：直接生成 comma-token。"]]]],["$","li",{},[["$","p",{},[["$","code",{},[":"]]," (冒号)：直接生成 colon-token。"]]]],["$","li",{},[["$","p",{},[["$","code",{},[";"]]," (分号)：直接生成 semicolon-token。"]]]],["$","li",{},[["$","p",{},[["$","code",{},["u"]]," 或 ",["$","code",{},["U"]],"：这是一个特殊前缀。如果其后是 + 紧跟着十六进制数字或 ? (例如 U+26 或 u+A?)，则调用 ",["$","code",{},["consumeUnicodeRangeToken()"]]," 解析为一个 urange-token。否则，按标识符处理。"]],["$","ul",{},[["$","li",{},["这里有一个坑点，需要在编写 parser 的时候注意，比如 ",["$","code",{},["u+a"]]," 既是一个合法的 unicode-range，也是一个合法的 selector，需要根据上下文来判定。"]]]]]],["$","li",{},[["$","p",{},["1 \u003c= c \u003c= 31, ",["$","code",{},["!"]],", ",["$","code",{},["%"]],", ",["$","code",{},["\u0026"]],", ",["$","code",{},["="]],", ",["$","code",{},["\u003e"]],", ",["$","code",{},["?"]],", ",["$","code",{},["`"]],", 127：解析为 delimiter-token。"]]]],["$","li",{},[["$","p",{},["其余字符：尝试解析为 ident-like。"]]]]]],["$","p",{},["整个流程在 ",["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/lexer.go#L24-L198","rel":"external nofollow noreferrer"},[["$","code",{},["lexer.go"]]," 的 24-198 行"]],"，由于篇幅原因此处就不贴完整代码了。"]],["$","h3",{"id":"token-解析"},["Token 解析"]],["$","p",{},["为了方便，我们为几种逻辑复杂 / 需要重用的 token 解析逻辑进行了封装，产生了如下函数："]],["$","ul",{},[["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume_token.go#L3-L16","rel":"external nofollow noreferrer"},[["$","code",{},["consumeNumericToken()"]]]]]],["$","ul",{},[["$","li",{},["先 consume 一个数字；"]],["$","li",{},["如果后续跟一个合法的 name，则 consume 这个 name 作为它的单位，组合为 dimension-token；"]],["$","li",{},["如果后续跟一个 ",["$","code",{},["%"]],"，consume 掉这个 ",["$","code",{},["%"]],"，产生一个 percentage-token；"]],["$","li",{},["否则产生一个 number-token。"]]]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-numeric-token"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeNumericToken() (TokenType, []",["$","span",{"class":"hljs-type"},["rune"]],") {\n    l.consumeNumber()\n\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," l.nextCharsAreIdentifier() {\n        l.consumeName()\n        ",["$","span",{"class":"hljs-keyword"},["return"]]," DimensionToken, l.r.Shift()\n    } ",["$","span",{"class":"hljs-keyword"},["else"]]," ",["$","span",{"class":"hljs-keyword"},["if"]]," l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],") == ",["$","span",{"class":"hljs-string"},["'%'"]]," {\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume '%'"]],"\n        ",["$","span",{"class":"hljs-keyword"},["return"]]," PercentageToken, l.r.Shift()\n    }\n\n    ",["$","span",{"class":"hljs-keyword"},["return"]]," NumberToken, l.r.Shift()\n}"]]]]]],["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume_token.go#L18-L43","rel":"external nofollow noreferrer"},[["$","code",{},["consumeUnicodeRangeToken()"]]]]]],["$","ul",{},[["$","li",{},["有以下几种情况：",["$","ul",{},[["$","li",{},[["$","code",{},["U+0000FF"]],"，",["$","code",{},["+"]]," 后面可以跟 1 ~ 6 个 16 进制数字；"]],["$","li",{},[["$","code",{},["U+0000??"]],"，",["$","code",{},["+"]]," 后面先跟 16 进制数字再跟 ",["$","code",{},["?"]],"（通配符），总数不超过 6 个；"]],["$","li",{},[["$","code",{},["U+0001-0002"]],"，",["$","code",{},["-"]]," 两侧可以有 1 ~ 6 个 16 进制数字。"]]]]]],["$","li",{},["这些情况需要各自分类讨论，最后产生一个 urange-token。"]]]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#urange"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeUnicodeRangeToken() (TokenType, []",["$","span",{"class":"hljs-type"},["rune"]],") {\n    ",["$","span",{"class":"hljs-comment"},["// range start"]],"\n    start_length_remaining := ",["$","span",{"class":"hljs-number"},["6"]],"\n    ",["$","span",{"class":"hljs-keyword"},["for"]]," next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],"); start_length_remaining \u003e ",["$","span",{"class":"hljs-number"},["0"]]," \u0026\u0026 next != EOF \u0026\u0026 isASCIIHexDigit(next); next = l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],") {\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the hex digit"]],"\n        start_length_remaining--\n    }\n\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," start_length_remaining \u003e ",["$","span",{"class":"hljs-number"},["0"]]," \u0026\u0026 l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],") == ",["$","span",{"class":"hljs-string"},["'?'"]]," { ",["$","span",{"class":"hljs-comment"},["// wildcard range"]],"\n        ",["$","span",{"class":"hljs-keyword"},["for"]]," start_length_remaining \u003e ",["$","span",{"class":"hljs-number"},["0"]]," \u0026\u0026 l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],") == ",["$","span",{"class":"hljs-string"},["'?'"]]," {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the '?'"]],"\n            start_length_remaining--\n        }\n    } ",["$","span",{"class":"hljs-keyword"},["else"]]," ",["$","span",{"class":"hljs-keyword"},["if"]]," l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],") == ",["$","span",{"class":"hljs-string"},["'-'"]]," \u0026\u0026 isASCIIHexDigit(l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],")) { ",["$","span",{"class":"hljs-comment"},["// range end"]],"\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the '-'"]],"\n\n        end_length_remaining := ",["$","span",{"class":"hljs-number"},["6"]],"\n        ",["$","span",{"class":"hljs-keyword"},["for"]]," next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],"); end_length_remaining \u003e ",["$","span",{"class":"hljs-number"},["0"]]," \u0026\u0026 next != EOF \u0026\u0026 isASCIIHexDigit(next); next = l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],") {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the hex digit"]],"\n            end_length_remaining--\n        }\n    }\n\n    ",["$","span",{"class":"hljs-keyword"},["return"]]," UnicodeRangeToken, l.r.Shift()\n}"]]]]]],["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume_token.go#L47-L68","rel":"external nofollow noreferrer"},[["$","code",{},["consumeIdentLikeToken()"]]]]]],["$","ul",{},[["$","li",{},["先 consume 一个合法的 name；"]],["$","li",{},["然后判断是否为一个函数的开始，如果是，再判断是否是 url-token，转入特定的解析流程。",["$","ul",{},[["$","li",{},["需要额外注意的是，如果 url 函数的参数是使用单 / 双引号包裹的字符串，那么按照普通函数参数解析即可。"]]]]]]]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-ident-like-token"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeIdentLikeToken() (TokenType, []",["$","span",{"class":"hljs-type"},["rune"]],") {\n    l.consumeName()\n\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],") == ",["$","span",{"class":"hljs-string"},["'('"]]," {\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the opening parenthesis"]],"\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," equalIgnoringASCIICase(l.r.Current(), urlRunes) {\n            ",["$","span",{"class":"hljs-comment"},["// The spec is slightly different so as to avoid dropping whitespace"]],"\n            ",["$","span",{"class":"hljs-comment"},["// tokens, but they wouldn't be used and this is easier."]],"\n            l.consumeWhitespace()\n\n            next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n            ",["$","span",{"class":"hljs-keyword"},["if"]]," next != ",["$","span",{"class":"hljs-string"},["'\"'"]]," \u0026\u0026 next != ",["$","span",{"class":"hljs-string"},["'\\''"]]," {\n                ",["$","span",{"class":"hljs-keyword"},["return"]]," l.consumeURLToken()\n            }\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["return"]]," FunctionToken, l.r.Shift()\n    }\n\n    ",["$","span",{"class":"hljs-keyword"},["return"]]," IdentToken, l.r.Shift()\n}"]]]],["$","p",{},["注意这里的实现其实会在含转义的 URL-token 上出现问题，后续通过修改 consumeName 函数的实现，通过返回值判断解决了此问题。"]]]],["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume_token.go#L70-L112","rel":"external nofollow noreferrer"},[["$","code",{},["consumeStringToken()"]]]]]],["$","ul",{},[["$","li",{},["简而言之，就是从开始的引号的位置一直匹配到相对应的结束引号位置或者文件末尾；"]],["$","li",{},["特别地，如果遇到没有转义的换行，那么此时就需要作为 bad-string-token 返回了。"]]]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-string-token"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeStringToken() (TokenType, []",["$","span",{"class":"hljs-type"},["rune"]],") {\n    until := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],") ",["$","span",{"class":"hljs-comment"},["// the opening quote, already checked valid by the caller"]],"\n    l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n\n    ",["$","span",{"class":"hljs-keyword"},["for"]]," {\n        next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," next == until {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n            ",["$","span",{"class":"hljs-keyword"},["return"]]," StringToken, l.r.Shift()\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," next == EOF {\n            ",["$","span",{"class":"hljs-keyword"},["return"]]," StringToken, l.r.Shift()\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," isCSSNewline(next) {\n            ",["$","span",{"class":"hljs-keyword"},["return"]]," BadStringToken, l.r.Shift()\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," next == ",["$","span",{"class":"hljs-string"},["'\\\\'"]]," {\n            next_next := l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],")\n\n            ",["$","span",{"class":"hljs-keyword"},["if"]]," next_next == EOF {\n                l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the backslash"]],"\n                ",["$","span",{"class":"hljs-keyword"},["continue"]],"\n            }\n\n            ",["$","span",{"class":"hljs-keyword"},["if"]]," isCSSNewline(next_next) {\n                l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n                l.consumeSingleWhitespace()\n            } ",["$","span",{"class":"hljs-keyword"},["else"]]," ",["$","span",{"class":"hljs-keyword"},["if"]]," twoCharsAreValidEscape(next, next_next) {\n                l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the backslash"]],"\n                l.consumeEscape()\n            } ",["$","span",{"class":"hljs-keyword"},["else"]]," {\n                l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n            }\n        } ",["$","span",{"class":"hljs-keyword"},["else"]]," {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the current rune"]],"\n        }\n    }\n}"]]]]]],["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume_token.go#L114-L164","rel":"external nofollow noreferrer"},[["$","code",{},["consumeURLToken()"]]]]]],["$","ul",{},[["$","li",{},["需要按照规范特别注意 bad-url-token 的情况。"]],["$","li",{},["但此处的实现和规范不同，在 ",["$","code",{},["consumeIdentLikeToken()"]]," 中我们把 URL 的前导空格全部 consume 掉了，但如果遇到使用引号包裹的 URL 时，这段空格理应单独作为一个 whitespace-token，不过无伤大雅，这样解析也可以，不影响后续的 parse 流程。"]]]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-url-token"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeURLToken() (TokenType, []",["$","span",{"class":"hljs-type"},["rune"]],") {\n    ",["$","span",{"class":"hljs-keyword"},["for"]]," {\n        next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," next == ",["$","span",{"class":"hljs-string"},["')'"]]," {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n            ",["$","span",{"class":"hljs-keyword"},["return"]]," UrlToken, l.r.Shift()\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," next == EOF {\n            ",["$","span",{"class":"hljs-keyword"},["return"]]," UrlToken, l.r.Shift()\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," isHTMLWhitespace(next) {\n            l.consumeWhitespace()\n\n            next_next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n            ",["$","span",{"class":"hljs-keyword"},["if"]]," next_next == ",["$","span",{"class":"hljs-string"},["')'"]]," {\n                l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the closing parenthesis"]],"\n                ",["$","span",{"class":"hljs-keyword"},["return"]]," UrlToken, l.r.Shift()\n            }\n            ",["$","span",{"class":"hljs-keyword"},["if"]]," next_next == EOF {\n                ",["$","span",{"class":"hljs-keyword"},["return"]]," UrlToken, l.r.Shift()\n            }\n\n            ",["$","span",{"class":"hljs-comment"},["// If the next character is not a closing parenthesis, there's an error and we should mark it as a bad URL token."]],"\n            ",["$","span",{"class":"hljs-keyword"},["break"]],"\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," next == ",["$","span",{"class":"hljs-string"},["'\"'"]]," || next == ",["$","span",{"class":"hljs-string"},["'\\''"]]," || isNonPrintableCodePoint(next) {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the invalid character"]],"\n            ",["$","span",{"class":"hljs-keyword"},["break"]],"\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," next == ",["$","span",{"class":"hljs-string"},["'\\\\'"]]," {\n            ",["$","span",{"class":"hljs-keyword"},["if"]]," twoCharsAreValidEscape(next, l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],")) {\n                l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the backslash"]],"\n                l.consumeEscape()\n                ",["$","span",{"class":"hljs-keyword"},["continue"]],"\n            } ",["$","span",{"class":"hljs-keyword"},["else"]]," {\n                ",["$","span",{"class":"hljs-keyword"},["break"]],"\n            }\n        }\n\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the current rune"]],"\n    }\n\n    l.consumeBadUrlRemnants()\n    ",["$","span",{"class":"hljs-keyword"},["return"]]," BadUrlToken, l.r.Shift()\n}"]]]]]]]],["$","h3",{"id":"特定类型字符片段解析"},["特定类型字符片段解析"]],["$","p",{},["一共有以下几个片段解析的函数："]],["$","ul",{},[["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L3-L19","rel":"external nofollow noreferrer"},[["$","code",{},["consumeUntilCommentEnd()"]]]],"：一直读取到注释结束。"]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-comment"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeUntilCommentEnd() {\n    ",["$","span",{"class":"hljs-keyword"},["for"]]," {\n        next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," next == EOF {\n            ",["$","span",{"class":"hljs-keyword"},["break"]],"\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," next == ",["$","span",{"class":"hljs-string"},["'*'"]]," \u0026\u0026 l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],") == ",["$","span",{"class":"hljs-string"},["'/'"]]," {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["2"]],") ",["$","span",{"class":"hljs-comment"},["// consume '*/'"]],"\n            ",["$","span",{"class":"hljs-keyword"},["return"]],"\n        }\n\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the current rune"]],"\n    }\n}"]]]]]],["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L21-L42","rel":"external nofollow noreferrer"},[["$","code",{},["consumeEscape()"]]]],"：解析一个转义字符。"]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-escaped-code-point"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeEscape() ",["$","span",{"class":"hljs-type"},["rune"]]," {\n    ",["$","span",{"class":"hljs-keyword"},["var"]]," res ",["$","span",{"class":"hljs-type"},["rune"]]," = ",["$","span",{"class":"hljs-number"},["0"]],"\n\n    next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," isASCIIHexDigit(next) {\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n        res = hexDigitToValue(next)\n\n        ",["$","span",{"class":"hljs-keyword"},["for"]]," i := ",["$","span",{"class":"hljs-number"},["1"]],"; i \u003c ",["$","span",{"class":"hljs-number"},["6"]],"; i++ {\n            c := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n            ",["$","span",{"class":"hljs-keyword"},["if"]]," isASCIIHexDigit(c) {\n                l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n                res = res*",["$","span",{"class":"hljs-number"},["16"]]," + hexDigitToValue(c)\n            } ",["$","span",{"class":"hljs-keyword"},["else"]]," {\n                ",["$","span",{"class":"hljs-keyword"},["break"]],"\n            }\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," !isValidCodePoint(res) {\n            res = ",["$","span",{"class":"hljs-string"},["'\\uFFFD'"]]," ",["$","span",{"class":"hljs-comment"},["// U+FFFD REPLACEMENT CHARACTER"]],"\n        }\n\n        ",["$","span",{"class":"hljs-comment"},["// If the next input code point is whitespace, consume it as well."]],"\n        l.consumeSingleWhitespace()\n    } ",["$","span",{"class":"hljs-keyword"},["else"]]," ",["$","span",{"class":"hljs-keyword"},["if"]]," next != EOF {\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the escape character"]],"\n        res = next\n    } ",["$","span",{"class":"hljs-keyword"},["else"]]," {\n        res = ",["$","span",{"class":"hljs-string"},["'\\uFFFD'"]]," ",["$","span",{"class":"hljs-comment"},["// U+FFFD REPLACEMENT CHARACTER for EOF"]],"\n    }\n\n    ",["$","span",{"class":"hljs-keyword"},["return"]]," res\n}"]]]]]],["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L44-L58","rel":"external nofollow noreferrer"},[["$","code",{},["consumeName()"]]]],"：读取一个 name。"]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-name"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeName() {\n    ",["$","span",{"class":"hljs-keyword"},["for"]]," {\n        next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," isNameCodePoint(next) {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n        } ",["$","span",{"class":"hljs-keyword"},["else"]]," ",["$","span",{"class":"hljs-keyword"},["if"]]," twoCharsAreValidEscape(next, l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],")) {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the backslash"]],"\n            l.consumeEscape()\n        } ",["$","span",{"class":"hljs-keyword"},["else"]]," {\n            ",["$","span",{"class":"hljs-keyword"},["break"]],"\n        }\n    }\n}"]]]]]],["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L60-L92","rel":"external nofollow noreferrer"},[["$","code",{},["consumeNumber()"]]]],"：读取一个数字。需要特别注意对科学计数法的处理，以及与调用侧配合正确解析 ",["$","code",{},[".7"]]," ",["$","code",{},["+.7"]]," 等 case。"]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-number"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeNumber() {\n    next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n\n    ",["$","span",{"class":"hljs-comment"},["// If the next rune is '+' or '-', consume it as part of the number."]],"\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," next == ",["$","span",{"class":"hljs-string"},["'+'"]]," || next == ",["$","span",{"class":"hljs-string"},["'-'"]]," {\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n    }\n\n    ",["$","span",{"class":"hljs-comment"},["// consume the integer part of the number"]],"\n    l.r.MoveWhilePredicate(isASCIIDigit)\n\n    ",["$","span",{"class":"hljs-comment"},["// float"]],"\n    next = l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," next == ",["$","span",{"class":"hljs-string"},["'.'"]]," \u0026\u0026 isASCIIDigit(l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],")) {\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the '.'"]],"\n        l.r.MoveWhilePredicate(isASCIIDigit)\n    }\n\n    ",["$","span",{"class":"hljs-comment"},["// scientific notation"]],"\n    next = l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," next == ",["$","span",{"class":"hljs-string"},["'e'"]]," || next == ",["$","span",{"class":"hljs-string"},["'E'"]]," {\n        next_next := l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],")\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," isASCIIDigit(next_next) {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume 'e' or 'E'"]],"\n            l.r.MoveWhilePredicate(isASCIIDigit)\n        } ",["$","span",{"class":"hljs-keyword"},["else"]]," ",["$","span",{"class":"hljs-keyword"},["if"]]," (next_next == ",["$","span",{"class":"hljs-string"},["'+'"]]," || next_next == ",["$","span",{"class":"hljs-string"},["'-'"]],") \u0026\u0026 isASCIIDigit(l.r.Peek(",["$","span",{"class":"hljs-number"},["2"]],")) {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["2"]],") ",["$","span",{"class":"hljs-comment"},["// consume 'e' or 'E' and the sign"]],"\n            l.r.MoveWhilePredicate(isASCIIDigit)\n        }\n    }\n}"]]]]]],["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L94-L101","rel":"external nofollow noreferrer"},[["$","code",{},["consumeSingleWhitespace()"]]]],"：读取一个空格。"]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeSingleWhitespace() {\n    next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," next == ",["$","span",{"class":"hljs-string"},["'\\r'"]]," \u0026\u0026 l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],") == ",["$","span",{"class":"hljs-string"},["'\\n'"]]," {\n        l.r.Move(",["$","span",{"class":"hljs-number"},["2"]],") ",["$","span",{"class":"hljs-comment"},["// consume CRLF"]],"\n    } ",["$","span",{"class":"hljs-keyword"},["else"]]," ",["$","span",{"class":"hljs-keyword"},["if"]]," isHTMLWhitespace(next) {\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the whitespace character"]],"\n    }\n}"]]]]]],["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L103-L115","rel":"external nofollow noreferrer"},[["$","code",{},["consumeWhitespace()"]]]],"：读取多个空格。"]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeWhitespace() {\n    ",["$","span",{"class":"hljs-keyword"},["for"]]," {\n        next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," isHTMLWhitespace(next) {\n            l.consumeSingleWhitespace()\n        } ",["$","span",{"class":"hljs-keyword"},["else"]]," ",["$","span",{"class":"hljs-keyword"},["if"]]," next == EOF {\n            ",["$","span",{"class":"hljs-keyword"},["return"]],"\n        } ",["$","span",{"class":"hljs-keyword"},["else"]]," {\n            ",["$","span",{"class":"hljs-keyword"},["break"]],"\n        }\n    }\n}"]]]]]],["$","li",{},[["$","p",{},[["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/consume.go#L117-L138","rel":"external nofollow noreferrer"},[["$","code",{},["consumeBadUrlRemnants()"]]]],"：读取 bad-url-token 的剩余部分。"]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#consume-the-remnants-of-a-bad-url"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," consumeBadUrlRemnants() {\n    ",["$","span",{"class":"hljs-keyword"},["for"]]," {\n        next := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," next == ",["$","span",{"class":"hljs-string"},["')'"]]," {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n            ",["$","span",{"class":"hljs-keyword"},["return"]],"\n        }\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," next == EOF {\n            ",["$","span",{"class":"hljs-keyword"},["return"]],"\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," twoCharsAreValidEscape(next, l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],")) {\n            l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],") ",["$","span",{"class":"hljs-comment"},["// consume the backslash"]],"\n            l.consumeEscape()\n            ",["$","span",{"class":"hljs-keyword"},["continue"]],"\n        }\n\n        l.r.Move(",["$","span",{"class":"hljs-number"},["1"]],")\n    }\n}"]]]]]]]],["$","h3",{"id":"identifier-和-number-的鉴别逻辑"},["Identifier 和 Number 的鉴别逻辑"]],["$","p",{},["对于 identifier，我们根据以下标准判断接下来的字符是否可能开始一个 identifier 的序列："]],["$","ul",{},[["$","li",{},["第一位是 NameStartCodePoint（以英文字母、下划线或非 ASCII 字母开始）；或"]],["$","li",{},["第一位和第二位组合起来可以开始一段转义序列；或"]],["$","li",{},["以 ",["$","code",{},["-"]]," 开始的 identifier（再走一遍上面两点的识别流程，同时注意 ",["$","code",{},["--"]]," 的情况）。"]]]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#would-start-an-identifier"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," nextCharsAreIdentifier() ",["$","span",{"class":"hljs-type"},["bool"]]," {\n    first := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," isNameStartCodePoint(first) {\n        ",["$","span",{"class":"hljs-keyword"},["return"]]," ",["$","span",{"class":"hljs-literal"},["true"]],"\n    }\n\n    second := l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],")\n\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," twoCharsAreValidEscape(first, second) {\n        ",["$","span",{"class":"hljs-keyword"},["return"]]," ",["$","span",{"class":"hljs-literal"},["true"]],"\n    }\n\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," first == ",["$","span",{"class":"hljs-string"},["'-'"]]," {\n        ",["$","span",{"class":"hljs-keyword"},["return"]]," isNameStartCodePoint(second) || second == ",["$","span",{"class":"hljs-string"},["'-'"]]," ||\n            twoCharsAreValidEscape(second, l.r.Peek(",["$","span",{"class":"hljs-number"},["2"]],"))\n    }\n\n    ",["$","span",{"class":"hljs-keyword"},["return"]]," ",["$","span",{"class":"hljs-literal"},["false"]],"\n}"]]]],["$","p",{},["对于 number，当符合以下条件的时候可以开始一个 number 的序列："]],["$","ul",{},[["$","li",{},["第一位是数字；"]],["$","li",{},["第一位是正负号，第二位是数字；"]],["$","li",{},["第一位是正负号，第二位是小数点，第三位是数字；"]],["$","li",{},["第一位是小数点，第二位是数字。"]]]],["$","pre",{},[["$","code",{"class":"hljs go"},[["$","span",{"class":"hljs-comment"},["// https://www.w3.org/TR/2021/CRD-css-syntax-3-20211224/#starts-with-a-number"]],"\n",["$","span",{"class":"hljs-function"},[["$","span",{"class":"hljs-keyword"},["func"]]," ",["$","span",{"class":"hljs-params"},["(l *Lexer)"]]]]," nextCharsAreNumber() ",["$","span",{"class":"hljs-type"},["bool"]]," {\n    first := l.r.Peek(",["$","span",{"class":"hljs-number"},["0"]],")\n\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," isASCIIDigit(first) {\n        ",["$","span",{"class":"hljs-keyword"},["return"]]," ",["$","span",{"class":"hljs-literal"},["true"]],"\n    }\n\n    second := l.r.Peek(",["$","span",{"class":"hljs-number"},["1"]],")\n\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," first == ",["$","span",{"class":"hljs-string"},["'+'"]]," || first == ",["$","span",{"class":"hljs-string"},["'-'"]]," {\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," isASCIIDigit(second) {\n            ",["$","span",{"class":"hljs-keyword"},["return"]]," ",["$","span",{"class":"hljs-literal"},["true"]],"\n        }\n\n        ",["$","span",{"class":"hljs-keyword"},["if"]]," second == ",["$","span",{"class":"hljs-string"},["'.'"]]," {\n            third := l.r.Peek(",["$","span",{"class":"hljs-number"},["2"]],")\n\n            ",["$","span",{"class":"hljs-keyword"},["if"]]," isASCIIDigit(third) {\n                ",["$","span",{"class":"hljs-keyword"},["return"]]," ",["$","span",{"class":"hljs-literal"},["true"]],"\n            }\n        }\n    }\n\n    ",["$","span",{"class":"hljs-keyword"},["if"]]," first == ",["$","span",{"class":"hljs-string"},["'.'"]]," {\n        ",["$","span",{"class":"hljs-keyword"},["return"]]," isASCIIDigit(second)\n    }\n\n    ",["$","span",{"class":"hljs-keyword"},["return"]]," ",["$","span",{"class":"hljs-literal"},["false"]],"\n}"]]]],["$","h3",{"id":"小结"},["小结"]],["$","p",{},["让我们来总结一下 lexer 工作流程：在 lexer 读取到某个 token 的起始点的时候，lexer 预读起始的几个字符，然后辨别 token 的类型。对于大致分类好的 token，根据其更具体的特征预读并消耗掉对应的字符，直到这个 token 结束。"]],["$","p",{},["大致的类型辨别是通过 ",["$","code",{},["Next()"]]," 函数中的那个巨大的 switch-case 语句来完成的。而对于精细的 token 类型的判断，则是 case 中的语句和 ",["$","code",{},["consume_token.go"]]," 定义的一系列函数来共同完成的。至于 token 内部的字符段的解析，则是 ",["$","code",{},["consume.go"]]," 中的一系列函数完成的。由此组合，整个 token 的解析过程得以良好运转。"]],["$","p",{},["除了文中提到的相关方法以外，在 ",["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/7c4a62d23d98865692e3633de64db503b56f6556/util.go","rel":"external nofollow noreferrer"},[["$","code",{},["util.go"]]]]," 中还有一系列的工具函数："]],["$","ul",{},[["$","li",{},[["$","code",{},["func isASCII(c rune) bool"]]]],["$","li",{},[["$","code",{},["func isASCIIAlpha(c rune) bool"]]]],["$","li",{},[["$","code",{},["func isASCIIDigit(c rune) bool"]]]],["$","li",{},[["$","code",{},["func isASCIIHexDigit(c rune) bool"]]]],["$","li",{},[["$","code",{},["func isCSSNewline(c rune) bool"]]]],["$","li",{},[["$","code",{},["func isNameStartCodePoint(r rune) bool"]]]],["$","li",{},[["$","code",{},["func isNameCodePoint(r rune) bool"]]]],["$","li",{},[["$","code",{},["func isNonPrintableCodePoint(r rune) bool"]]]],["$","li",{},[["$","code",{},["func twoCharsAreValidEscape(first, second rune) bool"]]]],["$","li",{},[["$","code",{},["func isHTMLSpecialWhitespace(c rune) bool"]]]],["$","li",{},[["$","code",{},["func isHTMLWhitespace(c rune) bool"]]]]]],["$","p",{},["这些函数的作用可以很容易地由它们的名字得知，故此处不再赘述。"]],["$","h2",{"id":"测试"},["测试"]],["$","p",{},["为了验证 lexer 的实现正确性，我们引入了 ",["$","a",{"href":"https://github.com/romainmenke/css-tokenizer-tests/tree/5e2112b59e728205a870ff130987e5204c425f59/tests","rel":"external nofollow noreferrer"},["romainmenke/css-tokenizer-tests"]]," 的测试用例来对 lexer 进行测试。具体的测试流程可以参考 ",["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer/blob/master/lexer_test.go","rel":"external nofollow noreferrer"},[["$","code",{},["lexer_test.go"]]]]," 中的实现。"]],["$","p",{},["根据测试结果来看，出现的问题主要集中在与转义字符相关的处理，对于大部分情况已经能够正常解析。截止编写本文之时，测试通过率为 96.53% (167/173)，个人认为已经处于可用水平。"]],["$","h2",{"id":"后记"},["后记"]],["$","p",{},["文中所述的 lexer 的具体实现已经开源在 ",["$","a",{"href":"https://github.com/renbaoshuo/go-css-lexer","rel":"external nofollow noreferrer"},["renbaoshuo/go-css-lexer"]],"，欢迎大家 Star！"]],["$","p",{},["搓这个 lexer 花了半个周末的时间，修修补补又消耗了一些时间。也算是在工作之余充实自己的大脑了。后续还可能会针对预读相关的内存访问进行优化（不知道读者有没有发现最多会预读三个字符），以提升处理效率。"]],["$","p",{},["文章题图由 Gemini 2.5 Pro Imagen 生成。"]]],"thumb":"https://s1.baoshuo.ren/2025/08/05/GeYRiDgPyqwrCLU.jpg","date":"2025-08-05","updated":"2026-01-21","isoDate":"2025-08-05T15:18:52.000Z","isoUpdate":"2026-01-21T07:35:27.000Z","categories":[{"name":"技术向","url":"/categories/%E6%8A%80%E6%9C%AF%E5%90%91/"}],"tags":[{"name":"CSS","url":"/tags/CSS/"},{"name":"编译原理","url":"/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"}],"license":null,"permalink":"https://blog.baoshuo.ren/post/css-lexer/","url":"/post/css-lexer/","prev":null,"next":{"title":"向着璀璨的未来进发 —— 我的 2024 年度总结","url":"/post/goodbye-2024/"},"toc":{"0":{"text":"词法分析","id":"词法分析"},"1":{"text":"Token 的分类","id":"token-的分类"},"2":{"text":"输入流","id":"输入流"},"3":{"0":{"text":"Token 开始处的分类讨论","id":"token-开始处的分类讨论"},"1":{"text":"Token 解析","id":"token-解析"},"2":{"text":"特定类型字符片段解析","id":"特定类型字符片段解析"},"3":{"text":"Identifier 和 Number 的鉴别逻辑","id":"identifier-和-number-的鉴别逻辑"},"4":{"text":"小结","id":"小结"},"text":"词法分析器","id":"词法分析器"},"4":{"text":"测试","id":"测试"},"5":{"text":"后记","id":"后记"}},"hasToc":true,"comments":true,"wordCount":"约 5.2 千字"}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"css-lexer"},"buildId":"byBUxtXb822vQt9-WWC4i","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>